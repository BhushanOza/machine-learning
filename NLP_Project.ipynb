{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boza5221_COMP5046_Ass1_2022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHoy6KpQDfZ"
      },
      "source": [
        "# 2022 COMP5046 Assignment 1\n",
        "*Make sure you change the file name with your unikey.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTf21j_oQIiD"
      },
      "source": [
        "# Readme\n",
        "Section 5 is stand-alone as required. Other sections can be run in ascending order. All required empirical evidences, explanations and justifications have been provided in relevant parts of section 4.\n",
        "\n",
        "*If there is something to be noted for the marker, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please check the bottom of the this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXbQohXLKSgO"
      },
      "source": [
        "***Visualising the comparison of different results is a good way to justify your decision.***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Data Preprocessing"
      ],
      "metadata": {
        "id": "A7v4GVxo4Dom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.0. Data Collection [DO NOT MODIFY THIS]"
      ],
      "metadata": {
        "id": "HftyG77k47Y3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f40e6f-8d8b-4aa6-de22-5b43102f0d03"
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '16g474hdNsaNx0_SnoKuqj2BuwSEGdnbt'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('training_data.csv')  \n",
        "\n",
        "id = '1-7hj0sF3Rc5G6POKdkpbDXm_Q6BWFDPU'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('testing_data.csv')  \n",
        "\n",
        "import pandas as pd\n",
        "training_data = pd.read_csv(\"/content/training_data.csv\")\n",
        "testing_data = pd.read_csv(\"/content/testing_data.csv\")\n",
        "\n",
        "print(\"------------------------------------\")\n",
        "print(\"Size of training dataset: {0}\".format(len(training_data)))\n",
        "print(\"Size of testing dataset: {0}\".format(len(testing_data)))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "print(\"------------------------------------\")\n",
        "print(\"Sample Data\")\n",
        "print(\"LABEL: {0} / SENTENCE: {1}\".format(training_data.iloc[-1,0], training_data.iloc[-1,1]))\n",
        "print(\"------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "Size of training dataset: 7808\n",
            "Size of testing dataset: 867\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "Sample Data\n",
            "LABEL: F / SENTENCE: 'Half of it is going straight to charity, another quarter going straight to scientific research, an eighth to the parkour community, a sixteenth to towards spreading information about health and...|||Find a path or suffer more.|||http://personalitycafe.com/enneagram-personality-theory-forum/85323-enneagram-type-mbti-type-compared-statistics.html yep.|||I kind of anchor on Fi and Ne makes having Ni really fun. INFP for me as they tire me out less and our views tend to align more.|||The two ESTPs I have gotten the chance to know seem to experience much more than other people who have been on the planet for the same amount of time and are quite the renaissance (wo)men.  Is this...|||I don't really have a best friend ISTP(passion-amateur group co-founder), INTJ(intellectual and various small hobbies talk), ESTP(Bro-in-law, talk about everything kind of like my INTJ friend),...|||Everyone looses their gift if they don't even consider a different perspective.|||Kansas - ISTJ|||That or if they are normally comfortable with me, such as a friend or close acquaintance, they feel the need to start talking. It's almost a trap, I've noticed for most people feel the need to expose...|||To me, your answers screamed introverted feeling. Answers 2-5, 10, 11, 14, 16, and 17 your last statement were particularly Fi-like. I'm guessing you are an intuitive and possibly and introvert...|||Could you explain your reasoning for these? I saw Mako as an F, Lin as an ES, and have Kya as an F. Never had an idea for Amon's type.|||This applies to many of these threads.|||With an INFP for over 2 years now.|||After watching tonight's episode I'm sure that Unalaq is an ENXJ. I'm not sure if it's Fe or Te at this point but the way he goes about doing and planning things seem like a Je-dom. I'm putting him...|||Parkour is my passion(but I consider it closer to a martial art than a sport). I also enjoy some running and climbing.|||I have many characters but I gravitate towards sneaky archer, Breton, and conjuration. I love doing role plays and think it's one of, if not the best way to play the game.|||ESFP seems right for Ikki. We may need Jinora to have more interactions for us to tell. Any guesses about Pema, Tenzin's wife? She said herself that she used to be very shy so I'd put I just from...|||If you don't mind, please tell me more by what you meant by this bolded part or what happened.|||I think it's fit to revive this thread seeing as the second season of Korra has started and the second episode of the season is coming up tomorrow. I'd just say beware of spoilers in new posts if you...|||I was thinking more along these lines: 83385|||Yes, a few times in friendships and other things but it was usually spurred on by the idea of not having a second chance. I've been trying to make the first move more in life as I've realized it just...|||Sorry if my wording was/is confusing or vague. Let me try to explain it better.  As for the first statement: I see the world for all it's interconnections. If you wish, visualized everything having...|||~I don't experience it as simply perceiving or creating, for me as I perceive interconnected relationships are formed and realized.   ~I don't think that I rationalize with my dominate function but...|||I think it's amusing that, in the leading position I share with an ISTP friend of mine, we both start to embrace our shadows. I Think that's been my growing point lately, embracing my shadow. We're...|||I would suggest introspection and relying on your sense of self over tests and I highly suggest looking into the cognitive functions. ISTJ is the complete opposite of INFJ.|||I definitely agree with others on the US- It's pretty good for an INFJ if you find your niche.  I say the Midwest is generally SJ with women expected to be F and men to be T. It's nice but annoying....|||Please explain|||I think my own eye movements have almost been changed because of where I was usually placed when talking to someone in normal conversations. See, when I was young I ended up getting permanent spot in...|||Judgmental, critical, somewhat narcissistic, stubborn, possessive, Fe-ishly manipulative, and I have ego issues. Take that with a grain of salt.|||Yes, very much so. I love Spanish so far.|||I have a huge folder of these types of images.|||Aquarian It was just my guess, it doesn't need that much merit. Personally, I think Se is the hardest function to describe because it is so in the moment.|||Sorry, double post because of connectivity weirdness.|||I don't know if this has been posted before or if a thread about curses would be the best place but it'll do just fine. The important part is post #79, the giant wall of text. I think most of it was...|||If anything, imo, Ni would be how objects are interconnected. If I were to follow closely to your model: Introverted Intuition: Understanding how objects are connected Extraverted Intuition:...|||Sometimes you just don't see them :ninja: Seriously, I thought I was alone in a small town but I was surprised after training for a couple months.  You can easily learn and train by yourself, you...|||82063 Stuff by Andy Day, not only do I like it because it is the stuff of my passion but that new perspective of our surroundings that it brings. This is a great example of that. All those people...|||Sorry for the quality, my relative only gave me a physical copy, it's a picture of a picture. This is my INFP girlfriend of two years and me.|||If I am with my SO I almost need physical contact in some way.|||I pretty much have a guru dream that involves my SP wannabe passion. Around people I am close to I totally put on the gypsy king face, people are just so interesting. Hahaha can't stop laughing at ...|||I agree this this post very much, I just can't shake that vibe. To me it feels like you are an INTP who strongly identifies with INFJs. I think if you want a sound answer form yourself and others we...|||I do pretty well in emergencies, I do very well compared to normal conditions in my opinion. I feel like I become the ideal version of myself, for the most part. It's hard to describe but it's like...|||I have a very close INTJ friend. The Te Fe difference is acknowledged very well and I'd say that both of our tertiary functions are well developed which helps a ton. He does not show it often but he...|||Being alone and/or doing something physical that I can naturally and reactively do without thinking or little thought.|||Pretty much this|||If I wear shoes or socks to bed and my feet are not on my bed I will wake up as if I was falling. 2/3 of the time this happens. Any other dreams that I remember(I don't remember most of my dreams...|||This one still gets me.  What I meant to say was Pass the salt but what I really said was You b****, you ruined my life|||I'm sorry, but I find them so funny because I use them for good reason. They make people uncomfortable at first but then, slowly, make people more comfortable with the idea that people are different...|||XSFJ Mother, ISTJ father, and an XNFJ sister. Yep.|||I love dark jokes, especially racists/stereotypical jokes.'\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview of the data in the csv file, which has two columns: \n",
        "# (1)type - label of the post (2)posts - the corresponding post content\n",
        "training_data.head()"
      ],
      "metadata": {
        "id": "WIHEbmSQp3fh",
        "outputId": "6cd870eb-eaad-44f0-ab25-ee674e89e059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  type                                              posts\n",
              "0    F  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "1    T  'I'm finding the lack of me in these posts ver...\n",
              "2    T  'Good one  _____   https://www.youtube.com/wat...\n",
              "3    T  'Dear INTP,   I enjoyed our conversation the o...\n",
              "4    T  'You're fired.|||That's another silly misconce..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48291c4d-4b68-422c-8ac5-7e4d642d3f18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48291c4d-4b68-422c-8ac5-7e4d642d3f18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48291c4d-4b68-422c-8ac5-7e4d642d3f18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48291c4d-4b68-422c-8ac5-7e4d642d3f18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the labels and posts and store into List\n",
        "\n",
        "# Get the list of training data (posts)\n",
        "training_posts=training_data['posts'].tolist()\n",
        "# Get the list of corresponding labels for the training data (posts)\n",
        "training_labels=training_data['type'].tolist()\n",
        "\n",
        "# Get the list of testing data (posts)\n",
        "testing_posts=testing_data['posts'].tolist()\n",
        "# Get the list of corresponding labels for the testing data (posts)\n",
        "testing_labels=testing_data['type'].tolist()"
      ],
      "metadata": {
        "id": "0SvGBOm9DvR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gBSgBCQh24"
      },
      "source": [
        "## 1.1. URL Removal\n",
        "*related to the section 4.2*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emyl1lWxGr12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ef3d651e-7ffc-4926-9443-19ec6817fc73"
      },
      "source": [
        "# need re for matching url\n",
        "import re \n",
        "\n",
        "# method for removing url and doing some basic cleaning/formatting for better experience later\n",
        "def url_remover(tx):\n",
        "    # escape the pipe separators\n",
        "    regex = re.compile('[%s]' % re.escape('|'))\n",
        "    tx = regex.sub(' ',tx)\n",
        "    # deal with words individually and remove those with http (i.e. url)\n",
        "    ws = str(tx).split()\n",
        "    ws = [x for x in ws if not 'http' in x]\n",
        "    # join the words when done, then return them\n",
        "    ws = ' '.join(ws)\n",
        "    return ws\n",
        "\n",
        "# apply the above method\n",
        "training_posts1 = training_data['posts'].apply(url_remover)\n",
        "# verify by checking 1st row\n",
        "training_posts1[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"enfp and intj moments sportscenter not top ten plays pranks What has been the most life-changing experience in your life? On repeat for most of today. May the PerC Experience immerse you. The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~ Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as... 84389 84390 ... Welcome and stuff. Game. Set. Match. Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative... Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by... All things in moderation. Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim... Dear ENFP: What were your favorite video games growing up and what are your now, current favorite video games? :cool: It appears to be too late. :sad: There's someone out there for everyone. Wait... I thought confidence was a good thing. I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to... Yo entp ladies... if you're into a complimentary personality,well, hey. ... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly. I really dig the part from 1:46 to 2:50 Banned because this thread requires it of me. Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses. Banned for too many b's in that sentence. How could you! Think of the B! Banned for watching movies in the corner with the dunces. Banned because Health class clearly taught you nothing about peer pressure. Banned for a whole host of reasons! 1) Two baby deer on left and right munching on a beetle in the middle. 2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall. 3) I see it as... a pokemon world an infj society everyone becomes an optimist 49142 Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature. Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud: Banned for taking all the room under my bed. Ya gotta learn to share with the roaches. Banned for being too much of a thundering, grumbling kind of storm... yep. Ahh... old high school music I haven't heard in ages. I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too... I like this person's mentality. He's a confirmed INTJ by the way. Move to the Denver area and start a new life for myself.'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Preprocess data (e.g. Stop words, Stemming)\n",
        "*related to the section 4.2*"
      ],
      "metadata": {
        "id": "QzLAO5a25qzS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl7t5Vqo5_gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4953f4-6614-4d63-efab-96866c78c756"
      },
      "source": [
        "# need re as earlier\n",
        "import re\n",
        "# remove punctuations and numbers, go lowercase \n",
        "def pln(x):\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    x = re.sub('^\\d+\\s|\\s\\d+\\s|\\s\\d+$','',x)\n",
        "    x = x.lower()\n",
        "    return x\n",
        "training_posts1 = training_posts1.apply(pln)\n",
        "\n",
        "# now, remove stopwords - need nltk for this\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.tokenize import word_tokenize\n",
        "def stopper(x):\n",
        "    tokens = word_tokenize(x)\n",
        "    stop_words = sw.words()\n",
        "    x = [w for w in tokens if not w in stop_words]\n",
        "    return x \n",
        "training_posts1 = training_posts1.apply(stopper)\n",
        "\n",
        "# encoding etc. done later"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gIzFi5NK68vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Input Representation\n"
      ],
      "metadata": {
        "id": "6sAZNIg5927R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daDvAftceIvr"
      },
      "source": [
        "## 2.1. Word Embedding Construction\n",
        "*related to the section 4.1 and 4.3*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw8I1QBk-EhG"
      },
      "source": [
        "# cbow, more processing done later\n",
        "from gensim.models import Word2Vec\n",
        "wv_cbow_model2 = Word2Vec(sentences=training_posts1, size=100, window=3, min_count=5, workers=2, sg=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNys5HOdISK-"
      },
      "source": [
        "## 2.2. Pretrained Word Embedding\n",
        "*related to the section 4.3*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8i7Z2kIef-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d22384-6b22-43d9-ba5e-3214cabace89"
      },
      "source": [
        "# more data processing\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "# glove\n",
        "import gensim.downloader as api\n",
        "word_emb_model1 = api.load(\"glove-twitter-25\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0ap96aeGlIk"
      },
      "source": [
        "## 2.3. Input Concatenation\n",
        "*related to the section 4.3*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2CUCL1cGlI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10898543-bef6-439b-c7a1-3acd1d00fbac"
      },
      "source": [
        "import numpy as np\n",
        "emb_dim = wv_cbow_model2.vector_size+word_emb_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model1 and word in wv_cbow_model2:\n",
        "        emb_table.append(np.concatenate((wv_cbow_model2[word],word_emb_model1[word]),0))\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIu_lkJwQ55g"
      },
      "source": [
        "# 3 - Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpYCL17JKZxl"
      },
      "source": [
        "### 3.1. Build Sequence Model (Bi-directional model)\n",
        "*related to the section 4.4*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13eCtR_SLUG6"
      },
      "source": [
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaOiaGRLW7R"
      },
      "source": [
        "### 3.2. Train Sequence Model (Bi-directional model)\n",
        "\n",
        "*related to the section 4.4*\n",
        "\n",
        "Note that it will not be marked if you do not display the Training Loss and the Number of Epochs in the Assignment 1 ipynb.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQnUSX1LZ6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c38c296-c0bd-4dba-d095-0c6cf0f25dde"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model1 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model1.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model1(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "    print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, loss: 0.69344, train_acc: 0.51\n",
            "Epoch: 2, loss: 0.68934, train_acc: 0.54\n",
            "Epoch: 3, loss: 0.68773, train_acc: 0.54\n",
            "Epoch: 4, loss: 0.68586, train_acc: 0.55\n",
            "Epoch: 5, loss: 0.68344, train_acc: 0.55\n",
            "Epoch: 6, loss: 0.68101, train_acc: 0.55\n",
            "Epoch: 7, loss: 0.67890, train_acc: 0.56\n",
            "Epoch: 8, loss: 0.67708, train_acc: 0.57\n",
            "Epoch: 9, loss: 0.67530, train_acc: 0.58\n",
            "Epoch: 10, loss: 0.67336, train_acc: 0.58\n",
            "Epoch: 11, loss: 0.67125, train_acc: 0.59\n",
            "Epoch: 12, loss: 0.66913, train_acc: 0.59\n",
            "Epoch: 13, loss: 0.66713, train_acc: 0.59\n",
            "Epoch: 14, loss: 0.66521, train_acc: 0.59\n",
            "Epoch: 15, loss: 0.66319, train_acc: 0.60\n",
            "Epoch: 16, loss: 0.66098, train_acc: 0.60\n",
            "Epoch: 17, loss: 0.65871, train_acc: 0.60\n",
            "Epoch: 18, loss: 0.65660, train_acc: 0.61\n",
            "Epoch: 19, loss: 0.65458, train_acc: 0.61\n",
            "Epoch: 20, loss: 0.65242, train_acc: 0.62\n",
            "Epoch: 21, loss: 0.65029, train_acc: 0.62\n",
            "Epoch: 22, loss: 0.64848, train_acc: 0.62\n",
            "Epoch: 23, loss: 0.64666, train_acc: 0.62\n",
            "Epoch: 24, loss: 0.64482, train_acc: 0.63\n",
            "Epoch: 25, loss: 0.64323, train_acc: 0.63\n",
            "Epoch: 26, loss: 0.64138, train_acc: 0.63\n",
            "Epoch: 27, loss: 0.63957, train_acc: 0.63\n",
            "Epoch: 28, loss: 0.63772, train_acc: 0.64\n",
            "Epoch: 29, loss: 0.63579, train_acc: 0.64\n",
            "Epoch: 30, loss: 0.63404, train_acc: 0.64\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4mpRpocePLN"
      },
      "source": [
        "# 4 - Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbLBzHObsvvM"
      },
      "source": [
        "## 4.1. Word Embedding Evaluation\n",
        "You are to apply Semantic-Syntactic word relationship tests for the trained word embeddings and visualise the result of Semantic-Syntactic word relationship tests.\n",
        "Note that it will not be marked if you do not display it in the ipynb file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSIUsb7qtQEf"
      },
      "source": [
        "(*Please show your empirical evidence and justification*):\n",
        "\n",
        "Empirical evidence:\n",
        "See below code cell's output.\n",
        "\n",
        "Explanation & Justification: \n",
        "1. Trend from graphs = higher the window size, worser the performance. Smaller window size tends to capture more about the word itself, larger window size tends to capture more about domain information - this could also explain the slightly different semantic accuracy trend. So, this dataset could be of a type where the word itself is more important.\n",
        "2. Trend from graphs = higher the dimensions, better the performance. Higher dimensions means a greater dimensional space that words can be mapped onto, so this could be the reason of this trend. But, sometimes overfitting can be an issue if too many dimensions are used - this could also explain the slightly different semantic accuracy trend.\n",
        "3. Hence, the highest chosen dimensions (100) and lowest chosen window size (3) have been used in the relevant sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCrcXwcGsuuo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "d9e95b90-8648-4c92-dc0a-2f942ef09621"
      },
      "source": [
        "# window size = 5 and dimensions = 100\n",
        "wv_cbow_model = Word2Vec(sentences=training_posts1, size=100, window=5, min_count=5, workers=2, sg=0)\n",
        "wv_cbow_model.wv.save_word2vec_format('cbow_w2v_1.txt', binary=False)\n",
        "!git clone https://github.com/stanfordnlp/GloVe.git\n",
        "vectors_file=\"/content/cbow_w2v_1.txt\"\n",
        "with open(vectors_file, 'r') as f:\n",
        "  vectors = {}\n",
        "  for line in f.readlines()[1:]: # we only need the embedding vectors starting from the second line \n",
        "    vals = line.rstrip().split(' ')\n",
        "    vectors[vals[0]] = [float(x) for x in vals[1:]]\n",
        "vocab_words=list(vectors.keys())\n",
        "vocab_size = len(vocab_words)\n",
        "\n",
        "# create word->index and index->word converter\n",
        "vocab = {w: idx for idx, w in enumerate(vocab_words)}\n",
        "ivocab = {idx: w for idx, w in enumerate(vocab_words)}\n",
        "# create the embedding matrix of shape (vocab_size, dim)\n",
        "vector_dim = len(vectors[ivocab[0]])\n",
        "W = np.zeros((vocab_size, vector_dim))\n",
        "for word, v in vectors.items():\n",
        "    if word == '<unk>':\n",
        "        continue\n",
        "    W[vocab[word], :] = v\n",
        "\n",
        "# normalize each word vector to unit length\n",
        "# Vectors are usually normalized to unit length before they are used for similarity calculation, making cosine similarity and dot-product equivalent.\n",
        "W_norm = np.zeros(W.shape)\n",
        "d = (np.sum(W ** 2, 1) ** (0.5))\n",
        "W_norm = (W.T / d).T\n",
        "def evaluate_vectors(W, vocab, prefix='./eval/question-data/'):\n",
        "    \"\"\"Evaluate the trained word vectors on a variety of tasks\"\"\"\n",
        "\n",
        "    filenames = [\n",
        "        'capital-common-countries.txt', 'capital-world.txt', 'currency.txt',\n",
        "        'city-in-state.txt', 'family.txt', 'gram1-adjective-to-adverb.txt',\n",
        "        'gram2-opposite.txt', 'gram3-comparative.txt', 'gram4-superlative.txt',\n",
        "        'gram5-present-participle.txt', 'gram6-nationality-adjective.txt',\n",
        "        'gram7-past-tense.txt', 'gram8-plural.txt', 'gram9-plural-verbs.txt',\n",
        "        ]\n",
        "\n",
        "    # to avoid memory overflow, could be increased/decreased\n",
        "    # depending on system and vocab size\n",
        "    split_size = 100\n",
        "\n",
        "    correct_sem = 0; # count correct semantic questions\n",
        "    correct_syn = 0; # count correct syntactic questions\n",
        "    correct_tot = 0 # count correct questions\n",
        "    count_sem = 0; # count all semantic questions\n",
        "    count_syn = 0; # count all syntactic questions\n",
        "    count_tot = 0 # count all questions\n",
        "    full_count = 0 # count all questions, including those with unknown words\n",
        "\n",
        "    for i in range(len(filenames)):\n",
        "        with open('%s/%s' % (prefix, filenames[i]), 'r') as f:\n",
        "            full_data = [line.rstrip().split(' ') for line in f]\n",
        "            full_count += len(full_data)\n",
        "            data = [x for x in full_data if all(word in vocab for word in x)]\n",
        "\n",
        "        if len(data) == 0: #line missing\n",
        "            continue\n",
        "\n",
        "        indices = np.array([[vocab[word] for word in row] for row in data])\n",
        "        ind1, ind2, ind3, ind4 = indices.T\n",
        "\n",
        "        predictions = np.zeros((len(indices),))\n",
        "        num_iter = int(np.ceil(len(indices) / float(split_size)))\n",
        "        for j in range(num_iter):\n",
        "            subset = np.arange(j*split_size, min((j + 1)*split_size, len(ind1)))\n",
        "\n",
        "            pred_vec = (W[ind2[subset], :] - W[ind1[subset], :]\n",
        "                +  W[ind3[subset], :])\n",
        "\n",
        "            #cosine similarity if input W has been normalized\n",
        "            dist = np.dot(W, pred_vec.T)\n",
        "\n",
        "\n",
        "            for k in range(len(subset)):\n",
        "                dist[ind1[subset[k]], k] = -np.Inf\n",
        "                dist[ind2[subset[k]], k] = -np.Inf\n",
        "                dist[ind3[subset[k]], k] = -np.Inf\n",
        "\n",
        "            # predicted word index\n",
        "            predictions[subset] = np.argmax(dist, 0).flatten()\n",
        "\n",
        "        \n",
        "        val = (ind4 == predictions) # correct predictions\n",
        "        count_tot = count_tot + len(ind1)\n",
        "        correct_tot = correct_tot + sum(val)\n",
        "        if i < 5:\n",
        "            count_sem = count_sem + len(ind1)\n",
        "            correct_sem = correct_sem + sum(val)\n",
        "        else:\n",
        "            count_syn = count_syn + len(ind1)\n",
        "            correct_syn = correct_syn + sum(val)\n",
        "\n",
        "\n",
        "        \n",
        "    return correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count\n",
        "\n",
        "correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count = evaluate_vectors(W_norm, vocab, prefix='/content/GloVe/eval/question-data')\n",
        "\n",
        "sem1 = (100 * correct_sem / float(count_sem), correct_sem, count_sem)\n",
        "\n",
        "syn1 = (100 * correct_syn / float(count_syn), correct_syn, count_syn)\n",
        "\n",
        "tot1 = (100 * correct_tot / float(count_tot), correct_tot, count_tot)\n",
        "###################################################################################################################################################################\n",
        "# different window size (window size = 3 and dimensions = 100)\n",
        "wv_cbow_model2.wv.save_word2vec_format('cbow_w2v_2.txt', binary=False)\n",
        "vectors_file=\"/content/cbow_w2v_2.txt\"\n",
        "with open(vectors_file, 'r') as f:\n",
        "  vectors = {}\n",
        "  for line in f.readlines()[1:]: # we only need the embedding vectors starting from the second line \n",
        "    vals = line.rstrip().split(' ')\n",
        "    vectors[vals[0]] = [float(x) for x in vals[1:]]\n",
        "vocab_words=list(vectors.keys())\n",
        "vocab_size = len(vocab_words)\n",
        "\n",
        "# create word->index and index->word converter\n",
        "vocab = {w: idx for idx, w in enumerate(vocab_words)}\n",
        "ivocab = {idx: w for idx, w in enumerate(vocab_words)}\n",
        "# create the embedding matrix of shape (vocab_size, dim)\n",
        "vector_dim = len(vectors[ivocab[0]])\n",
        "W = np.zeros((vocab_size, vector_dim))\n",
        "for word, v in vectors.items():\n",
        "    if word == '<unk>':\n",
        "        continue\n",
        "    W[vocab[word], :] = v\n",
        "\n",
        "# normalize each word vector to unit length\n",
        "# Vectors are usually normalized to unit length before they are used for similarity calculation, making cosine similarity and dot-product equivalent.\n",
        "W_norm = np.zeros(W.shape)\n",
        "d = (np.sum(W ** 2, 1) ** (0.5))\n",
        "W_norm = (W.T / d).T\n",
        "def evaluate_vectors(W, vocab, prefix='./eval/question-data/'):\n",
        "    \"\"\"Evaluate the trained word vectors on a variety of tasks\"\"\"\n",
        "\n",
        "    filenames = [\n",
        "        'capital-common-countries.txt', 'capital-world.txt', 'currency.txt',\n",
        "        'city-in-state.txt', 'family.txt', 'gram1-adjective-to-adverb.txt',\n",
        "        'gram2-opposite.txt', 'gram3-comparative.txt', 'gram4-superlative.txt',\n",
        "        'gram5-present-participle.txt', 'gram6-nationality-adjective.txt',\n",
        "        'gram7-past-tense.txt', 'gram8-plural.txt', 'gram9-plural-verbs.txt',\n",
        "        ]\n",
        "\n",
        "    # to avoid memory overflow, could be increased/decreased\n",
        "    # depending on system and vocab size\n",
        "    split_size = 100\n",
        "\n",
        "    correct_sem = 0; # count correct semantic questions\n",
        "    correct_syn = 0; # count correct syntactic questions\n",
        "    correct_tot = 0 # count correct questions\n",
        "    count_sem = 0; # count all semantic questions\n",
        "    count_syn = 0; # count all syntactic questions\n",
        "    count_tot = 0 # count all questions\n",
        "    full_count = 0 # count all questions, including those with unknown words\n",
        "\n",
        "    for i in range(len(filenames)):\n",
        "        with open('%s/%s' % (prefix, filenames[i]), 'r') as f:\n",
        "            full_data = [line.rstrip().split(' ') for line in f]\n",
        "            full_count += len(full_data)\n",
        "            data = [x for x in full_data if all(word in vocab for word in x)]\n",
        "\n",
        "        if len(data) == 0: #line missing\n",
        "            continue\n",
        "\n",
        "        indices = np.array([[vocab[word] for word in row] for row in data])\n",
        "        ind1, ind2, ind3, ind4 = indices.T\n",
        "\n",
        "        predictions = np.zeros((len(indices),))\n",
        "        num_iter = int(np.ceil(len(indices) / float(split_size)))\n",
        "        for j in range(num_iter):\n",
        "            subset = np.arange(j*split_size, min((j + 1)*split_size, len(ind1)))\n",
        "\n",
        "            pred_vec = (W[ind2[subset], :] - W[ind1[subset], :]\n",
        "                +  W[ind3[subset], :])\n",
        "\n",
        "            #cosine similarity if input W has been normalized\n",
        "            dist = np.dot(W, pred_vec.T)\n",
        "\n",
        "\n",
        "            for k in range(len(subset)):\n",
        "                dist[ind1[subset[k]], k] = -np.Inf\n",
        "                dist[ind2[subset[k]], k] = -np.Inf\n",
        "                dist[ind3[subset[k]], k] = -np.Inf\n",
        "\n",
        "            # predicted word index\n",
        "            predictions[subset] = np.argmax(dist, 0).flatten()\n",
        "\n",
        "        \n",
        "        val = (ind4 == predictions) # correct predictions\n",
        "        count_tot = count_tot + len(ind1)\n",
        "        correct_tot = correct_tot + sum(val)\n",
        "        if i < 5:\n",
        "            count_sem = count_sem + len(ind1)\n",
        "            correct_sem = correct_sem + sum(val)\n",
        "        else:\n",
        "            count_syn = count_syn + len(ind1)\n",
        "            correct_syn = correct_syn + sum(val)\n",
        "\n",
        "        \n",
        "    return correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count\n",
        "\n",
        "correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count = evaluate_vectors(W_norm, vocab, prefix='/content/GloVe/eval/question-data')\n",
        "\n",
        "sem2 = (100 * correct_sem / float(count_sem), correct_sem, count_sem)\n",
        "\n",
        "syn2 = (100 * correct_syn / float(count_syn), correct_syn, count_syn)\n",
        "\n",
        "tot2 = (100 * correct_tot / float(count_tot), correct_tot, count_tot)\n",
        "###################################################################################################################################################################\n",
        "# different dimensions (window size = 3 and dimensions = 50)\n",
        "wv_cbow_model3 = Word2Vec(sentences=training_posts1, size=50, window=3, min_count=5, workers=2, sg=0)\n",
        "wv_cbow_model3.wv.save_word2vec_format('cbow_w2v_3.txt', binary=False)\n",
        "vectors_file=\"/content/cbow_w2v_3.txt\"\n",
        "with open(vectors_file, 'r') as f:\n",
        "  vectors = {}\n",
        "  for line in f.readlines()[1:]: # we only need the embedding vectors starting from the second line \n",
        "    vals = line.rstrip().split(' ')\n",
        "    vectors[vals[0]] = [float(x) for x in vals[1:]]\n",
        "vocab_words=list(vectors.keys())\n",
        "vocab_size = len(vocab_words)\n",
        "\n",
        "# create word->index and index->word converter\n",
        "vocab = {w: idx for idx, w in enumerate(vocab_words)}\n",
        "ivocab = {idx: w for idx, w in enumerate(vocab_words)}\n",
        "# create the embedding matrix of shape (vocab_size, dim)\n",
        "vector_dim = len(vectors[ivocab[0]])\n",
        "W = np.zeros((vocab_size, vector_dim))\n",
        "for word, v in vectors.items():\n",
        "    if word == '<unk>':\n",
        "        continue\n",
        "    W[vocab[word], :] = v\n",
        "\n",
        "# normalize each word vector to unit length\n",
        "# Vectors are usually normalized to unit length before they are used for similarity calculation, making cosine similarity and dot-product equivalent.\n",
        "W_norm = np.zeros(W.shape)\n",
        "d = (np.sum(W ** 2, 1) ** (0.5))\n",
        "W_norm = (W.T / d).T\n",
        "def evaluate_vectors(W, vocab, prefix='./eval/question-data/'):\n",
        "    \"\"\"Evaluate the trained word vectors on a variety of tasks\"\"\"\n",
        "\n",
        "    filenames = [\n",
        "        'capital-common-countries.txt', 'capital-world.txt', 'currency.txt',\n",
        "        'city-in-state.txt', 'family.txt', 'gram1-adjective-to-adverb.txt',\n",
        "        'gram2-opposite.txt', 'gram3-comparative.txt', 'gram4-superlative.txt',\n",
        "        'gram5-present-participle.txt', 'gram6-nationality-adjective.txt',\n",
        "        'gram7-past-tense.txt', 'gram8-plural.txt', 'gram9-plural-verbs.txt',\n",
        "        ]\n",
        "\n",
        "    # to avoid memory overflow, could be increased/decreased\n",
        "    # depending on system and vocab size\n",
        "    split_size = 100\n",
        "\n",
        "    correct_sem = 0; # count correct semantic questions\n",
        "    correct_syn = 0; # count correct syntactic questions\n",
        "    correct_tot = 0 # count correct questions\n",
        "    count_sem = 0; # count all semantic questions\n",
        "    count_syn = 0; # count all syntactic questions\n",
        "    count_tot = 0 # count all questions\n",
        "    full_count = 0 # count all questions, including those with unknown words\n",
        "\n",
        "    for i in range(len(filenames)):\n",
        "        with open('%s/%s' % (prefix, filenames[i]), 'r') as f:\n",
        "            full_data = [line.rstrip().split(' ') for line in f]\n",
        "            full_count += len(full_data)\n",
        "            data = [x for x in full_data if all(word in vocab for word in x)]\n",
        "\n",
        "        if len(data) == 0: #line missing\n",
        "            continue\n",
        "\n",
        "        indices = np.array([[vocab[word] for word in row] for row in data])\n",
        "        ind1, ind2, ind3, ind4 = indices.T\n",
        "\n",
        "        predictions = np.zeros((len(indices),))\n",
        "        num_iter = int(np.ceil(len(indices) / float(split_size)))\n",
        "        for j in range(num_iter):\n",
        "            subset = np.arange(j*split_size, min((j + 1)*split_size, len(ind1)))\n",
        "\n",
        "            pred_vec = (W[ind2[subset], :] - W[ind1[subset], :]\n",
        "                +  W[ind3[subset], :])\n",
        "\n",
        "            #cosine similarity if input W has been normalized\n",
        "            dist = np.dot(W, pred_vec.T)\n",
        "\n",
        "\n",
        "            for k in range(len(subset)):\n",
        "                dist[ind1[subset[k]], k] = -np.Inf\n",
        "                dist[ind2[subset[k]], k] = -np.Inf\n",
        "                dist[ind3[subset[k]], k] = -np.Inf\n",
        "\n",
        "            # predicted word index\n",
        "            predictions[subset] = np.argmax(dist, 0).flatten()\n",
        "\n",
        "        \n",
        "        val = (ind4 == predictions) # correct predictions\n",
        "        count_tot = count_tot + len(ind1)\n",
        "        correct_tot = correct_tot + sum(val)\n",
        "        if i < 5:\n",
        "            count_sem = count_sem + len(ind1)\n",
        "            correct_sem = correct_sem + sum(val)\n",
        "        else:\n",
        "            count_syn = count_syn + len(ind1)\n",
        "            correct_syn = correct_syn + sum(val)\n",
        "\n",
        "\n",
        "        \n",
        "    return correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count\n",
        "\n",
        "correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count = evaluate_vectors(W_norm, vocab, prefix='/content/GloVe/eval/question-data')\n",
        "\n",
        "sem3 = (100 * correct_sem / float(count_sem), correct_sem, count_sem)\n",
        "\n",
        "syn3 = (100 * correct_syn / float(count_syn), correct_syn, count_syn)\n",
        "\n",
        "tot3 = (100 * correct_tot / float(count_tot), correct_tot, count_tot)\n",
        "###################################################################################################################################################################\n",
        "# different dimensions again (window size = 3 and dimensions = 25)\n",
        "wv_cbow_model4 = Word2Vec(sentences=training_posts1, size=25, window=3, min_count=5, workers=2, sg=0)\n",
        "wv_cbow_model4.wv.save_word2vec_format('cbow_w2v_4.txt', binary=False)\n",
        "vectors_file=\"/content/cbow_w2v_4.txt\"\n",
        "with open(vectors_file, 'r') as f:\n",
        "  vectors = {}\n",
        "  for line in f.readlines()[1:]: # we only need the embedding vectors starting from the second line \n",
        "    vals = line.rstrip().split(' ')\n",
        "    vectors[vals[0]] = [float(x) for x in vals[1:]]\n",
        "vocab_words=list(vectors.keys())\n",
        "vocab_size = len(vocab_words)\n",
        "\n",
        "# create word->index and index->word converter\n",
        "vocab = {w: idx for idx, w in enumerate(vocab_words)}\n",
        "ivocab = {idx: w for idx, w in enumerate(vocab_words)}\n",
        "# create the embedding matrix of shape (vocab_size, dim)\n",
        "vector_dim = len(vectors[ivocab[0]])\n",
        "W = np.zeros((vocab_size, vector_dim))\n",
        "for word, v in vectors.items():\n",
        "    if word == '<unk>':\n",
        "        continue\n",
        "    W[vocab[word], :] = v\n",
        "\n",
        "# normalize each word vector to unit length\n",
        "# Vectors are usually normalized to unit length before they are used for similarity calculation, making cosine similarity and dot-product equivalent.\n",
        "W_norm = np.zeros(W.shape)\n",
        "d = (np.sum(W ** 2, 1) ** (0.5))\n",
        "W_norm = (W.T / d).T\n",
        "def evaluate_vectors(W, vocab, prefix='./eval/question-data/'):\n",
        "    \"\"\"Evaluate the trained word vectors on a variety of tasks\"\"\"\n",
        "\n",
        "    filenames = [\n",
        "        'capital-common-countries.txt', 'capital-world.txt', 'currency.txt',\n",
        "        'city-in-state.txt', 'family.txt', 'gram1-adjective-to-adverb.txt',\n",
        "        'gram2-opposite.txt', 'gram3-comparative.txt', 'gram4-superlative.txt',\n",
        "        'gram5-present-participle.txt', 'gram6-nationality-adjective.txt',\n",
        "        'gram7-past-tense.txt', 'gram8-plural.txt', 'gram9-plural-verbs.txt',\n",
        "        ]\n",
        "\n",
        "    # to avoid memory overflow, could be increased/decreased\n",
        "    # depending on system and vocab size\n",
        "    split_size = 100\n",
        "\n",
        "    correct_sem = 0; # count correct semantic questions\n",
        "    correct_syn = 0; # count correct syntactic questions\n",
        "    correct_tot = 0 # count correct questions\n",
        "    count_sem = 0; # count all semantic questions\n",
        "    count_syn = 0; # count all syntactic questions\n",
        "    count_tot = 0 # count all questions\n",
        "    full_count = 0 # count all questions, including those with unknown words\n",
        "\n",
        "    for i in range(len(filenames)):\n",
        "        with open('%s/%s' % (prefix, filenames[i]), 'r') as f:\n",
        "            full_data = [line.rstrip().split(' ') for line in f]\n",
        "            full_count += len(full_data)\n",
        "            data = [x for x in full_data if all(word in vocab for word in x)]\n",
        "\n",
        "        if len(data) == 0: #line missing\n",
        "            continue\n",
        "\n",
        "        indices = np.array([[vocab[word] for word in row] for row in data])\n",
        "        ind1, ind2, ind3, ind4 = indices.T\n",
        "\n",
        "        predictions = np.zeros((len(indices),))\n",
        "        num_iter = int(np.ceil(len(indices) / float(split_size)))\n",
        "        for j in range(num_iter):\n",
        "            subset = np.arange(j*split_size, min((j + 1)*split_size, len(ind1)))\n",
        "\n",
        "            pred_vec = (W[ind2[subset], :] - W[ind1[subset], :]\n",
        "                +  W[ind3[subset], :])\n",
        "\n",
        "            #cosine similarity if input W has been normalized\n",
        "            dist = np.dot(W, pred_vec.T)\n",
        "\n",
        "\n",
        "            for k in range(len(subset)):\n",
        "                dist[ind1[subset[k]], k] = -np.Inf\n",
        "                dist[ind2[subset[k]], k] = -np.Inf\n",
        "                dist[ind3[subset[k]], k] = -np.Inf\n",
        "\n",
        "            # predicted word index\n",
        "            predictions[subset] = np.argmax(dist, 0).flatten()\n",
        "\n",
        "        \n",
        "        val = (ind4 == predictions) # correct predictions\n",
        "        count_tot = count_tot + len(ind1)\n",
        "        correct_tot = correct_tot + sum(val)\n",
        "        if i < 5:\n",
        "            count_sem = count_sem + len(ind1)\n",
        "            correct_sem = correct_sem + sum(val)\n",
        "        else:\n",
        "            count_syn = count_syn + len(ind1)\n",
        "            correct_syn = correct_syn + sum(val)\n",
        "\n",
        "\n",
        "        \n",
        "    return correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count\n",
        "\n",
        "correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count = evaluate_vectors(W_norm, vocab, prefix='/content/GloVe/eval/question-data')\n",
        "\n",
        "sem4 = (100 * correct_sem / float(count_sem), correct_sem, count_sem)\n",
        "\n",
        "syn4 = (100 * correct_syn / float(count_syn), correct_syn, count_syn)\n",
        "\n",
        "tot4 = (100 * correct_tot / float(count_tot), correct_tot, count_tot)\n",
        "###################################################################################################################################################################\n",
        "# graphing based on window sizes\n",
        "import matplotlib.pyplot as plt\n",
        "windows = [3,5]\n",
        "accuracy1_sem = [sem2[0],sem1[0]]\n",
        "accuracy1_syn = [syn2[0],syn1[0]]\n",
        "accuracy1_tot = [tot2[0],tot1[0]]\n",
        "plt.plot(windows,accuracy1_sem,label='semantic accuracy',marker='o')\n",
        "plt.plot(windows,accuracy1_syn,label='syntactic accuracy',marker='o')\n",
        "plt.plot(windows,accuracy1_tot,label='overall accuracy',marker='o')\n",
        "plt.title('Peformance trend based on different window sizes (dimensions=100)')\n",
        "plt.xlabel('Window sizes')\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# graphing based on dimensions\n",
        "dims = [25,50,100]\n",
        "accuracy2_sem = [sem4[0],sem3[0],sem1[0]]\n",
        "accuracy2_syn = [syn4[0],syn3[0],syn1[0]]\n",
        "accuracy2_tot = [tot4[0],tot3[0],tot1[0]]\n",
        "plt.plot(dims,accuracy2_sem,label='semantic accuracy',marker='o')\n",
        "plt.plot(dims,accuracy2_syn,label='syntactic accuracy',marker='o')\n",
        "plt.plot(dims,accuracy2_tot,label='overall accuracy',marker='o')\n",
        "plt.title('Peformance trend based on different dimensions (window size=3)')\n",
        "plt.xlabel('Dimensions')\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GloVe'...\n",
            "remote: Enumerating objects: 606, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 606 (delta 5), reused 7 (delta 2), pack-reused 592\u001b[K\n",
            "Receiving objects: 100% (606/606), 224.91 KiB | 12.50 MiB/s, done.\n",
            "Resolving deltas: 100% (343/343), done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEWCAYAAABWn/G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gUVdvA4d9J7wkkoSckgHQIJQKKCoKACtIUsaAIAgqKwCcIKipiw1d9FTtFUERRREURFRUEfAGVUKQJIhAgtARIJz3n+2M2yaZssglJJuW5rytXdmenPDs7O8+eM2fOUVprhBBCiMriYHYAQgghahdJPEIIISqVJB4hhBCVShKPEEKISiWJRwghRKWSxCOEEKJSVXjiUUrVV0ptVkolKqVeq+jt1UZKqRCllFZKOdl4PVIpdUNlx1Ugho1KqXEmbHeOUmq55XGwUipJKeVoeZ7v2FSGpUqpWKXUn5Uda2kppXorpaKsnu9XSvU2MaR8lFJ3K6V+MmG7LymlppZymTLHWtL3ryKZtY+LopT6Uil1kz3z2p14LCevFMsX95xS6kOllJcdi04AzgM+WutH7d1edVYVTvSiMK31Ca21l9Y6yzKp4LF5DdAPaKK17laZsZXHyUtr3U5rvbEcw7osWutPtNb9K3ObSqlA4F5gQWmWMyPW8lCZcSulrldK7VVKxSmlLiilvlZKNbaa5WXgeXvWVdoSzy1aay+gCxAOzLZjmabAAV2GO1XN+AVRGWrq+6qGCh6bTYFIrXVyaVckn2mVcR/wvdY6xexAaqADwACttR/QCDgMvJfzotb6T8BHKRVe4pq01nb9AZHADVbPXwG+szzuAWwF4oC/gN6W6R8CGUA6kATcALgCbwCnLX9vAK6W+XsDUcBM4CzwMTAH+AJYDiQCe4GWwONANHAS6G8V1xjgb8u8R4EHrF7LWf+jlmXPAGOsXncHXgOOA/HA/wD34t5jEfvpYyAbSLG858eAEEAD9wMngM2WecdaYo0F1gFNrdajgQcxPtw44B1AWV5zBF7F+LV+FHjIMr9TMZ/d4xgHTiywFHCzvFYH+A6Isbz2HcYv/pxl77NsIxE4Btxt9Vpx8fcDDlr249vAJmCcjfjsOSaK/MyKWFeoZVuJwM+WbS+3vJbzOThR+Nh8AEgFsizPn7UsMwjYbfkMtgIdC+zXmcAeIM2yXpvHCbAReA7YYonvJyDA8toJS2xJlr+rinhv7pa4Yy2f5QwgqqjvKKX/3vgCH1j27ymMX66OVsfA/zCOuVjLcXBTScdIznJW810NbLccE9uBq+3cN26W93HBsl+3A/VtfP4bgFFWzzcBt1oe97Ts44GW532B3TZiLfP3D+Ok/C1wEfgXGG/1PlKs3teTQCZGiRvL+3/DxvsqcR9jnGuSrP4ygA9L+nzL8ofxnX0J44eb9fRFwDMlLl+KDUWSd1AHAfstO6qx5YC4GaME1c/yPFDnJZ/nrdYzF/gdqAcEYnxJn7M6yWRiFNlcMb5oczBOCAMwvtjLLDv+ScAZGA8cs1r/QKA5oIBewCWgS4H1z7Use7Pl9TqW19/B+AI0thxcV1viKPY9FrevCpzwlgGelvc1BOOgbGN5X7OBrQUO/O8APyAYIzHcaHntQYyTehBQF/iVkhPPPqv5t+R8JoA/cCvgAXhjnKxWW17zBBKAVpbnDYF2lsc24wcCML4gt1n28zTLfreVeOw5Jor8zIpY1zbgv5bP7TpLHIUSj41j8z7yn3w6Y5yku1uOh9GWfelqtV93W/are0nHCcaxdQQjAbhbns8rKjYb720e8JvlMwyyfKbFJZ7SfG++xqie8rR8Dn9i+dFm2S8ZlmUcgYkYPxAUxR8jufvTEnMscI8lnjstz/3t2DcPAGswjlFHoCuWk3UR+ygGuLLAsfWW5fETlm28bPXafBuffZm/f8Bm4F2MRNPJsmwfq9dyEuFPlnhusnptWBHvya59XGCZIMtnlLPu4j7fazCSq62/a6zWG2yZlm05Ju4rsN3/A74q78STZNnoccuOdcf4xfdxgXnXAaNtfLmPADdbPR+AUb0BxkkmHcuvcasv0M9Wz2+xxJHza8zb8qH72Yh7NTDFav0pWH25MU4sPTBOFClAWBHrKPY92thXRSWeZlbTfgDut3rugHFCbWp14Ft/4CuBWZbHG4AHrV7rT8mJx3r+m4EjNubtBMRaHfBxGInJvcB8NuPHqGP/3eo1hVFqsZV4SjomivzMilhPMEaS8rSa9illTzzvYUmAVtMOAb2s9utYe48TjJPpbKvXJgE/FhWbjf10FMvJz/J8AsUnHru+N0B9jBKbu9X8dwK/Wu2Xf61e87As26CEYyR3f2IknD8LvL4Ny4mrhH0zlgKlzWL2UQbQ2up5X2CP5fGPwDgsxyZGaWi4jc++TN8/jBN+FuBt9fpL5JU8ngPetMx7FpiC8YMipzTkX8R7smsfW01zB3YAMy3Pi/18y/KHkXBnUuB7iPHjZENJy5f2Gs9QrbWf1rqp1nqSNupRmwIjLBec4pRScRgZtKGNdTTCSFw5jlum5YjRWqcWWOac1eMU4LzOu0CcU5frBaCUukkp9btS6qIllpsxfoHnuKC1zrR6fsmybADGh3+kiJhL+x5tOVlgnfOt1ncR4wRtfbHubBFxgrG/rNdlvT/t2XbuPldKeSilFiiljiulEjB+dfkppRy1ca1jJMYvvDNKqbVKqdZ2xJ8vPm0ckdbbL6ikY8LWZ1bUemJ1/ms09uwbW5oCjxb43IMKxFbwMy3pOLH1mdqjtJ+7vd+bphiloDNWcS/A+GVcKG6t9aWcZUs4RgrGXjDe49h3vH+MkcA/U0qdVkr9RynlbOM9x2Ik1RzbgJZKqfoYP6qWAUFKqQCgG8bxbktZvn+NgIta68QCr+e8z00YP6a6YFR//oxRM9MDI7lfKBhEKfZxjg+AQ1rrly3P7fl8S0VrfRH4CPimwPVNb4wkWazyaE59EuNXnp/Vn6fWep6N+U9j7IgcwZZpOXRZA1FKuQJfYtS/1tfGRbDvMU6IJTmPUTXRvIjXSvsebb0H6+knMYq61ut011pvtSPWMxgnwBzBdixTcP6cff4o0ArorrX2waieAss+01qv01r3wzh5HsSowy0p/nzxKaVUge0XVNIxYa8zQB2llGeBdZXVSeCFAu/RQ2u9wmqegp9paY4Ta/Yc92X53O1xEuMXcYBV3D5a63b2LFzMMWKt4GcMRvyn7Fh/htb6Wa11W4zq70EYpeqi7MGorstZ9hLGr/8pwD6tdTpG6en/MEr950vafhGK+xxOA3WVUt4FXs95n1sxvm/DgE1a6wOW12/GSEpFsnMfo5SahfH+77eaXOznq5S61tJa2dbftTbCcsJIXj5W09pgXNssVnkknuXALUqpAUopR6WUm+X+giY25l8BzFZKBVp+dTxtWUd5cMGo248BMi1tyu1qaqi1zgaWAP9VSjWyvJerLMmstO/xHNCshE2+DzyulMr58H2VUiPsiRWj2P+IUqqJUqoOMMuOZR6yzF8Xo57/c8t0b4xfv3GW157JWUAZ97kMsZzI0zCqarLtiH8t0E4pNdzya+gRjGoZW8rlmNBaHwcigGeVUi5KqWswqpjKahHwoFKquzJ4KqUGFjipWCvtcWItBmPfFnfcrMTY53Us65xcqndjg9b6DMb1hteUUj5KKQelVHOlVK+Sli3hGLH2PUbJ4y6llJNSaiTQFuM6SknbuF4p1UEZ918lYFSnFbWNnO0UjHsT8DB5J/aNBZ6Xls3vn9b6JEZyecny+XfESALLLa/nJMKHrLa/FaM0U2Q89u5jy/nuEYzrRLmt+kr6fLXWv2njNgNbf79Z1j9cKdXKsnwgxrXUXZbST45eGNXwxbrsxGPZ0UMwLtzFYGTXGcWs+3mMk8MejKLmTuxs+21HLIkYO34lRpH7LozWJfaabolpO0bV0cuAQxne40sYJ9I4pdR0G7F+bVn/Z5Yqrn2AXTdfYZwQ12H8stgJfGXHMp9iHHxHMaoTc/b5Gxh1wucxLvD/aLWMA8Yvw9MY+6MXxoXlYuO3/IocgVF3fQG4AqNBgy3leUzchdEY4CJGEl1WxvWgtY7AqLN+G+N4+hejTt3W/KU9TqyXvQS8AGyxHDc9ipjtWYxqm2MYn+XHpXg7JbkX44dbTsvHVdhXlWzzGLFmqUIahFHCvoDRAmuQnSWOBpZ4EjBaUW7C9ntfBtyslHK3mrYJ4wfWZhvPS6uk79+dGNfsTmNc1H9Ga/1LgXicMS7w2xOPXfsYozouEPjbqrTyvuW1sn6+1hpjnB9yWklmY5TcAFBKXQkkaaNZdbFymgcKIUSNoJR6EYjWWr9hdiy1iVLqS+ADrfX3Jc4riUcIIURlkk5ChRBCVCpJPEIIISqVJB4hhBCVqlp0bBgQEKBDQkLMDkMIIaqVHTt2nNdaB5odR0HVIvGEhIQQERFhdhhCCFGtKKUup+eOCiNVbUIIISqVJB4hhBCVShKPEEKISiWJRwghRKWSxCOEEKJSSeIRQoiqaM9KeL09zPEz/u9ZaXZE5aZaNKcWQohaZc9KWPMIZFhGN4g/aTwH6Hi7eXGVEynxCCFEVZKVCT89lZd0cmSkwPq55sRUzqTEI4QQZtAaEk5D9AE4t9/y/wCcPwRZ6UUvEx9VuTFWEEk8QghR0VLjIfrv/Akm+gCkxuXN490I6reF5tfDruWQcrHwenztGcy26pPEI4QQ5SUzHS4ctiSW/XkJJv5k3jyuPlCvDbQbBvXbQb22RsJxr5M3T4MO+a/xADi7Q9+nK++9VCBJPEIIUVpaG9Ve+arJ9sP5w5CdYczj4AQBLSGoO4SPgXrtjATjGwRKFb/+nAYE6+ca2/FtYiSdGtCwACTxCCFE8VLiCl+Hif4b0uLz5vENMkouLQfkJRj/K8DJpcybXevlyfygRpyt60ADzwZM8fJkYDm8napAEo8QQgBkpsH5fwpXkyWcypvHzddILB1HWKrI2hnVZm6+5RrK2qNrmbN1DqlZqQCcST7DnK1zABjYrPqnH0k8QojaJTsb4k8UTjAX/oXsTGMeB2cIbAVNexqll3rtjCTj06jkarJyMH/n/NykkyM1K5X5O+dL4hFCiCrt0sX812CiLdVk6Ul58/gFG4ml9cC8Uox/C3B0rvDwUjNTOZ5wnGMJx4iMj+RY/DGOxR/jTPKZIuc/m3y2wmOqDJJ4hBDVX0aqcf+LdSnm3H5IsjpRu9cxEkynu/ISTGBrcPOp0NC01lxIvZCbVI7FH8tNNKeTTqPRufM28mxEiG8IHk4eXMq8VGhdDTwbVGislUUSjxCi+sjOhrjIvOqxnFLMhSOgs4x5HF2NarLm1+c1Va7XDrwbVGg1WXpWOicTT+Yml8iEvBJMUkZeCcvdyZ0QnxA6BnRkSPMhhPqGEuIbQlOfprg7uQOFr/EAuDm6MaXLlAqLvzJJ4hFCVE3J54uoJjsIGcmWGRTUCTFKLm2H5iWYus3AsWJObVprYtNi81WL5SSYqKQosnV27rz1POoR6hvKwGYDCfUNNf58QqnvWR8HVXxvZTnXcebvnM/Z5LNGq7YuU2rE9R0ApbUueS6ThYeH64iICLPDEEJUhPRLEHPQqqmypaosOTpvHg9/q1ZkVtVkrl4VElJGdgZRiVFGgkmwJBjL43irZtQuDi409W1KqI9RaslJMCE+IXg6e1ZIbKWhlNqhtQ43O46CpMQjhKgc2Vlw8ZhVSzLL/4tHIec6h5ObkVCu6Je/msyrXoVUk8WnxeerEsspwZxMOEmmzsydz9/Nn1DfUPo37U+IT16CaejZEEcHx3KPq6aTxCOEKH9J0XBuX/5rMTGHIDOnCxhlVInVbwsdRlhVk4VCOZ/Is7KzOJ10OrfkYl09djE1rz80Jwcngr2DaebbjL7BfXMTTIhvCD4uFdsAobaRxCOEKLv0ZOO6S8FSzKXzefN41jMSS/hYS4Jpa5RqXDzKNZSk9KR8pZecxycSTpCendfbs5+rH6G+ofQO6p2v9NLYqzFODnJKrAyyl4UQJcvKNKrErG+4PLcfYiPJrSZz9jDu4m91U/5rMZ4B5RZGts7mbPLZQq3GIuMjiU7JuybkqBxp4t2EUJ9Qrm18be71lxCfEOq41SlmC6IySOIRQuTRGhLPFk4wMYcgK82YRzlA3ebQsCOE3ZlXiqkTCg7lM7bkpYxLxo2VBRLM8YTj+ZoYezt7E+obSo9GPXJbjYX6hhLkHYRzJdwAKspGEo8QtVVaYhFjxOyHlNi8ebwaGIkl9Lq8UkxgK6OL/suktSb6UnT+VmOWmyut79BXKBp7NSbEN4RuDbvlllxCfUPxd/NHVUIXNqJ8SeIRoqbLyjD6ISuYYOJO5M3j4mVUk7UZnL+azKPuZW8+LSstt/RiXYKJjI/Md3e+h5MHob6hdK3fNbfkknNjpauj62XHIaoOSTxC1BT2DKWsHCHgCmgcDl3utRojJviyqsmK6hYmJ8EU7BamoWdDQn1DGdpiaL77Xup51JPSSy0hiUeI6qjIoZT3G9Nz+DQ2Si4t+uQlmICW4FT20kNGVgYnEk8UvrEy/hiJGYm587k5uhHia3QLM7j54NwEE+wdjIdz+bZmE9WPJB4hqrJSDaU83PZQyqUUmxpbuOVYQiRRiVFk5fSJBtRzN7qFubnZzfku7tvTLYyovSTxCFEVaG0kk4IJpryGUi5CZnYmUYlRRSaYuLS43PlcHFwI9gmmZZ2WDAgZQIhPCM18m9HUpyleLhXTZY2o2STxCFHZUmIL964c/TekJeTNU45DKVt3C2Pdcuxk4kkys/N3CxPiG8INTW/I1/dYI89G0i2MKFeSeISoKNZDKZ/bl3ctJvF03jy5QynffllDKWdlZ3E6+XS+zixzHl9IvZA7n5NyItgnmFCfUPoE9cltORbiE4Kva/kO3yyELZJ4hLhctoZSPn/YaowYFwhoBaHX5u9luZRDKSdnJBMZH8nR+KP5qscKdgvj6+pLM99mXNfkunwtxxp7N8bZQW6sFOaSxCNEaZRqKOVBeZ1f+je3eyjlbJ3NueRzuVVi1lVktrqFuabxNfkSjHQLI6oySTxCFCUj1WqMGKsmyyUNpVyvDbh627WJlMyU/DdWWqrIIuMjpVsYUaNJ4hG1W3Y2xB4rPAjZxSOQM5rkZQylnNMtTFG9Jp9JPpM7n0LRyKsRob6hXNngyny9Jku3MKKmkcQjao98QylbxoqJOQgZOd22WA2l3G5YqYZSzukWxrrVWM7jgt3ChPiG0KV+l3wtx4K9g3Fzcqu49y5EFSKJR9Q8dg2lHGAkli6j8xJMvdbgYnu4YutuYQp2yX8q6VShbmFCfEJyu4UJ8Q0h1CdUuoURAkk8ojor7VDK1p1fetWzudqMrAxOJp4sfHE/4RiJ6YW7hWkf0J5bmt+Se2G/qU9T6RZGiGJI4hFVn9bGUMpFjRFzGUMpx6XGFdklv81uYULzuoUJ8Q2hgWcD6RZGiDKQxCMq156VsH4uxEeBbxPo+7Rx82SOtCSjmqxgk+VLeTdBlmYo5czsTE4V0SX/sfhj+bqFcXZwpqlPU1rWaUn/pv0J9Q2VbmGEqCAVlniUUkuAQUC01rq9ZdorwC1AOnAEGKO1jrO9FlGj7FkJax6BDEspJf4kfPMQ7F9tPI/eD7HHKTyU8s0lDqWckJ5AZMyeQgnmROKJfN3C1HWrS6hvKDc0vSFfyzHpFkaIyqO01iXPVZYVK3UdkAQss0o8/YENWutMpdTLAFrrmSWtKzw8XEdERFRInKISvd4+f6/K1gJa5r+jv35b8AvJN0ZMTrcwRbUcK9gtTJBPUL7BxHKuv0i3MKI2UUrt0FqHmx1HQRVW4tFab1ZKhRSY9pPV09+B2ypq+6IKio9iracH8+v4cdbJkQaZWUyJjWNgcgo8vD13tuSMZKPEEvl9vhLM8fjjhbqFCfUJze0WJqcEI93CCFG1mXmNZyzwua0XlVITgAkAwcHBlRWTqCjRB1nr5cEc/zqkWkoxZ5ydeDrAny0+4PH787nVY9GX8po9OygHgryDCPEJoWejnvkSjHQLI0T1VGFVbQCWEs93OVVtVtOfBMKB4dqOAKSqrZo7uw+WDaG/vytnnIq+jpLTLUxOtVhOy7Eg7yBcHEs/FIAQohZWtdmilLoPo9FBX3uSjqjmTu+Cj4eBswdnbSQdhWLLnVvkxkohaolKvQlBKXUj8BgwWGt9qaT5RTV3cjt8NARcvDkxYjHKxj0vDTwbSNIRohapsMSjlFoBbANaKaWilFL3A28D3sDPSqndSqn3K2r7wmTHt8LHQ8GjLsdHLGLM70/h5uBWqNrMzdGNKV2mmBSkEMIMFdmq7c4iJn9QUdsTVcjRTbDiDvBpzLHh73L/lllk6SyWD1zOP7H/MH/nfM4mn6WBZwOmdJnCwGYDzY5YCFGJpOcCUb7+/QU+uxvqNuPo0Le4/38zyNbZfND/A1rUacEVda6QRCNELScdTYnyc+gHWHEnBFzBkWFvM/a36WitWTJgCS3qtDA7OiFEFSGJR5SPA9/A56OgfnsOD3mDsZv/D6UUS25cQnO/5mZHJ4SoQiTxiMu3dxV8MQYad+Wfwa8xbvOjOCpHlgxYQjPfZmZHJ4SoYiTxiMuz+1P4ajwEX8WhgfMYt3EqTg5OLL1xKaG+oWZHJ4SogiTxiLLb8SGsngSh13Hw5hcYt3EKLo4uLB2wlKY+Tc2OTghRRUmrNlE2fyyEH2bAFf05cMOTTPj1Ydyd3FnSfwlBPkFmRyeEqMKkxCNKb+tbRtJpNZD9NzzJuA2T8HTyZOmApZJ0hBAlkhKPKJ3Nr8KG56DtUPb1msaEDZPwcfHhgwEf0NirsdnRCSGqAUk8wj5aw8aXYNPL0HEke3pO5MH1k/Bx9WHJgCU08mpkdoRCiGpCEo8omdbwyxzY8gZ0HsXuHvczcf0k/Fz9WHrjUhp4NjA7QiFENSKJRxRPa/jxcfjjPQi/n93ho3hw/ST83fz5YMAHknSEEKUmiUfYlp0N30+HiA+g+0R2dh7BxPUTqedRj8X9F1Pfs77ZEQohqiFJPKJo2Vmw5hHYtRx6TmVHh1uYuH4i9T3q88GAD6jnUc/sCIUQ1ZQkHlFYViZ8Mwn2fA69ZrK9dT8eWj+JBp4N+KD/BwR6BJodoRCiGpPEI/LLyoAvx8GB1dDnKf684joe3vAQjTwbsXjAYgLcA8yOUAhRzUniEXky04zOPg+thf7P83volUxe/xBNvJuwuP9i/N39zY5QCFEDSOIRhoxUWHkPHP4JbnqFrUHteWT9wwT7BLO4/2LqutU1O0IhRA0hiUdA+iX47E5jyOpBb7ClYUseWT+ZUN9QFvVfRB23OmZHKISoQSTx1HZpSfDpSDixFYa+y28BQUzd8AjN/JqxqN8i/Nz8zI5QCFHDSOKpzVLj4ZMREBUBwxexuU49pv46hRZ+LVjUfxG+rr5mRyiEqIEk8dRWKbHw8XA4uwdGLGWjty/Tfp1CyzotWdhvoSQdIUSFkcRTGyVfgI+HQMwhGLmcDe6uPLpxGq3rtGZB/wX4uPiYHaEQogaTxFPbJEXDR4Mh9hjcuYL1zorpGx+lrX9b3u/3Pt4u3mZHKISo4WQguNok4TQsvRnijsNdK/nZWTN903TaBbRjQb8FknSEEJVCEk9tEXfSSDqJZ2DUl6xzSGXGphm0D2jP+ze8j5eLl9kRCiFqCUk8tUFsJHx4M1y6CPes5sfsBGZunklYYBjv95OkI4SoXJJ4aroLR4ySTloijP6GtRnRzPxtJp3qdeK9G97D09nT7AiFELWMJJ6aLPogLL3J6INt9BrWpETxxP+eoGv9rrzb9108nD3MjlAIUQvZ3apNKdUCmAO4A69qrbdVVFCiHJzdB8uGgIMj3LeWbxP/Yfb/ZtOtQTfe6vsW7k7upoS1etcpXll3iNNxKTTyc2fGgFYM7dzYlFiEEOawmXiUUm5a61SrSc8Bj1kerwE6VWRg4jKc3g0fDwUndxi9htVx+3h6y9N0b9idN/u8aWrSefyrvaRkZAFwKi6Fx7/aCyDJR4hapLiqtjVKqXutnmcAIUBTIKsigxKXISrCuE/HxRvGfM/XsXt5esvTXNXoKt7qY15JB+CVdYdyk06OlIwsXvj+b2IS08jO1iZFJoSoTMVVtd0ITFRK/Qi8CEwHHsGoaru7EmITpXV8m9H3mmcAjP6WVdF/8uy2Z+nZuCfzr5+Pq6OrqeGdjkspcnpMYhpXvvALjg6KAC8X6nm7Uc/blXo+rgR6u1HfxzXftAAvV5wd5fKkENWVzcSjtc4C3lZKfQw8BUwEZmutj1RWcKIUjm02epn2aQyjv2Xlmf/x3O/PcW3ja3n9+tdNTzoAPu5OxKdkFppe18OZKTe0JDoxlXMJaUQnpnEqLoXdJ+O4kJxeaH6loK6HC4HertTzMRJSweRUz9uNQG9X3JwdK+OtCSFKobhrPN2BGUA6RoknBXhBKXUKeE5rHVc5IYoS/bsePrsL6oTCvd/w2alfeeGPF+jVpBf/7f1fXBxdzI6QjYeiiU/JxEGBdY2au7MjT9/SzuY1noysbM4npRFtSUg5ySkmMTV32qGzCZxPSieriKo6Hzcnq+Rk/LdOWPUsj71cpfcoISpLcd+2BcDNgBewVGvdE7hDKdUL+BwYUAnxiZIc+tEYOTSgFdy7mk9P/MRLf75E76DevNbrtSqRdP6NTmLyp7to3cCbMVeH8OaGf+1u1ebs6EBDX3ca+hZ/bSorW3MxOZ3oxFSiE9OISUjjXEJqbrKKTkzjz2MXiUlMIz0ru9DyHi6OuUnISEhulpJT/se+7s4opS57nwhRmxWXeDIxGhN4YpR6ANBabwI2VWxYwi5/r4EvxkCD9jDqKz45/gPz/pxHn6A+vNrrVZwdnc2OkLhL6Yz7aDsuTg4sHh1OkzoejOwWXO7bcXRQBFpKM+2KmU9rTXxKhpGQikhOMQlp7DsVT3RiNJfSC7ehcXFyyCspFUhOgVaP/T1dcHCQBCVEUYpLPHcBD2AknXuLmU+YYd+X8OV4aNwVRq1i2ZFveCXiFW4IvoH/9PoPzg7mJ53MrLuzHRIAACAASURBVGwe/nQXp+JSWDG+B03qmH/DqlIKPw8X/DxcaFm/+E5Rk9IyibYkpnMJqcQkWqr7LNP+jUli65HzJKQWvm7l6KAI9HLNTUyBBa4/SUMJUZsV17jgH+DRSoxF2Gv3CvhmEgRfBXd9zkf/fsWrEa/Sr2k/Xr7u5SqRdACeX/s3//v3PP+5rSPhIXXNDqfUvFyd8Ar0ollg8X3ZpWZkEZNoVXrKLUUZf1GxKew6YbuhhL+nS15iKpSc8q5LSUMJUVNU2BVVpdQSYBAQrbVub5lWF+P6UAgQCdyutY6tqBhqpB0fwZopEHod3LmCJf98zus7XmdAyABeuvalKpN0PvnjOB9ujWTcNaHcHh5kdjgVys3ZkaC6HgTVLb5El9NQ4lxC/uRk3VDiYDENJXzdnQslpkCrRhM5ScpTGkqIKq4ij9APgbeBZVbTZgHrtdbzlFKzLM9nVmAMNcufi+D76dCiH4z8mMUHP2H+zvncFHoTL17zIk4OVeOEs+3IBZ75Zj+9Wgby+M1tzA6nyihNQ4kLycY1qJic609WrfpKaijh6eJIPR+jOXnONaf6PgVKUt5u+Lg7SUMJYYoSz1RKqVuAtVrrwkd4MbTWm5VSIQUmDwF6Wx5/BGxEEo99tr0D656AVgNhxFIWHviIt3a9xcBmA3m+5/NVJumcuHCJSZ/soKm/B2/d1RlHucBeao4OypIg3IqdT2tN3KWMvIRUIDnlNJQ4lxBdqMcIAFcnhyKSU/6EVc/Hlboe0lBClC97zlYjgTeUUl8CS7TWBy9je/W11mcsj88C9W3NqJSaAEwACA4u/1ZQ1cpvr8H6udB2KNy6mPf2Lebd3e9yS7NbeK7nczg6VI26/8TUDMYt2062hsWjr8THrWpU+9VUSinqeLpQx9OFVg1sN5TQWhsNJRJz7ocq3FDicHQiW46cJ7GIhhJODooAL6sSk3Uzc6uqvwAvF5ykoYSwQ4mJR2s9SinlA9wJfKiU0sBSYIXWOrGsG9Zaa8u6bL2+EFgIEB4eXjs78dIaNs6DTfOgw+3oIe/y3t5FvPfXewxpPoRnr362yiSdrGzN1M92cyQmmWVjuxEaIOP8VBVKKbzdnPF2c6a5HQ0lcpJT0Q0lLrHzRCwXS2goUb+Ie6CsW/a5OlWN41aYw676Ga11glJqFUY/bVOBYcAMpdSbWuu3SrG9c0qphlrrM0qphkB06UOuJbSG9c/C/16HTqPQt8znnT3vs2DPAoa1GMacq+fgoKrOr8tX1h1i/cFo5g5pR88WAWaHI8rIzdmRYH8Pgv2LbyiRnmnpUSKxcEOJc5bEdeB0AueT0iiq71dfd+d83RwF5rv+JA0lajp7rvEMBsYALTAaCnTTWkcrpTyAA0BpEs+3wGhgnuX/N6WOuDbQGtY9Cb+/A+Fj0Te9ylt/vcOivYu49Ypbefqqp6tU0vlqZxTvbzrC3d2DuadHU7PDEZXAxcmBRn7uNPIrW0OJc1bXpI6dT7bZUMLL1clGN0d516UCvd3wcZOGEtWJPT8nbgVe11pvtp6otb6klLrf1kJKqRUYDQkClFJRwDMYCWelZbnjwO1lDbzGys6GH2bA9sXQfSJ6wIvM3/UmH+z7gNta3sZTPZ6qUkln54lYZn21lx7N6jJncDv58ot8LrehRN6Nu6nsiYojOiHNZkOJekWUmvI1N/d2pY40lKgSlNbFXz5RSoUCZ3IGhVNKuWM0Eois+PAM4eHhOiIiorI2Z57sLPhuKuxcBj2noPvO4fWdb7B0/1JGthrJE92fqFJJ53RcCoPf3oKHiyPfPNSTOp7m9wsnaraiGkrkvyaV99hWQ4mcVnuBVtef6hfoo8/fs2Y0lFBK7dBah5sdR0H2lHi+AK62ep5lmXZlhURUW2VlwjcPwZ7P4LrH0L0f59Udr7HswDLuaHUHT3R/okqVJlLSs5jwcQSpGVl8Or67JB1RKUrTUCIlPSuvei9fzxLGtJIbSlhX61n3bm7dYEIaSpSFPYnHSWtt3UloulJKzjLlKSsDvpoA+7+CPrPR107nP9v/w/K/l3N3m7uZeeXMKpV0tNZM/+Iv9p9OYPG94SX2eSaEGdxdytZQ4lxiGjH5WvMV31DCz8O5QPPyovvl83ApXUOJ1btO8cq6Q3b35F6d2LMnYpRSg7XW3wIopYYA5ys2rFokMx1WjYGD30G/59BXT+bl7S/zyd+fMKrNKB678rEqlXQA3lz/L2v3nuHxm1rTt43NW7GEqBbK0lCi0A27Vg0lohNTycgqnKGsG0rUt5GcchpKfLP7NI9/tTf3etapuBQe/2ovQI1IPvYkngeBT5RSbwMKOIn0Vl0+MlJh5b1weB3c9B90twm8+MeLfHboM0a3Hc2j4Y9WuaTzw94zvP7LPwzv3JgJ1zUzOxwhKk3+hhK+NufLaShxrojklFP191cxDSXcnB3IyNKF+utLycjilXWHakfisQx13UMp5WV5nlThUdUG6ZeMUUOPboRBb5DddTQv/vECnx/6nDHtxjCt67Qql3T2nYrn/1b+RedgP14c3qHKxSdEVWDdo0TrBrbny2kocc66NwnL40W/HStymdNxKRUUdeWyq9JRKTUQaAe45ZxstNZzKzCumi0tCVbcAZH/gyHvkN3pTp77/TlW/bOK+9vfz5QuU6rcST0mMY0JyyLw83BmwT1dpYt+IS6TdUOJFvXyN5T4fu9ZThWRZEqqDqwuSmwvqJR6H6O/tskYVW0jALlLsKxSE2D5rXB8KwxfRHanO5m7bS6r/lnF+A7jq2TSScvM4oGPI7h4KZ1F94aXeE+GEOLyzBjQCvcCP+7cnR2ZMaCVSRGVL3saql+ttb4XiNVaPwtcBbSs2LBqqJRY+HgonIqAEUvJ7nArz2x9hi8Pf8kDHR9gcufJVS7paK15/Ku97DwRx2sjOtG+se26bSFE+RjauTEvDe9AYz93FNDYz52XhneoEdd3wL6qtlTL/0tKqUbABaBhxYVUQyVfMJJOzEEYuZysK/rz9Jan+PbIt0wKm8TEThPNjrBIi347ylc7TzGl7xUM7CgfuxCVZWjnxjUm0RRkT+JZo5TyA14BdgIaWFShUdU0SdGwbChcPAJ3rCCr+fU8teUp1hxdw6ROk5gYVjWTzq8Ho3nph4Pc3KEBU/peYXY4QogaotjEo5RywBgxNA74Uin1HeCmtY6vlOhqgoQzsGwwxEfBXZ+TGXINs7c8ydqja5nceTITOk4wO8IiHT6XyOQVu2jb0IdXR4RJ/1ZCiHJT7DUey6ij71g9T5OkUwrxUfDhzZBwGkZ9SWbINTzx2xOsPbqWKV2mVNmkE5uczrhlEbg5O7Lo3vBS33EthBDFsadxwXql1K2qql31rupiI2HpTca1nXtWkxnUjVm/zeKHyB+Y1nUa4zqMMzvCImVkZTPpk52ciUtlwT1da0zzTSFE1WHPT9kHgP8DMpVSqRhNqrXW2qdCI6vOLhyBjwZDehKM/oaMBu2Zufkxfj7+M9PDpzO63WizI7Tp2TX72Xb0Aq+NCKNr0zpmhyOEqIHs6blAeoAsjZhDRtLJzoD7viMjsDWPbXqMX078wozwGdzbrur2NvTxtkiW/36CB65rxq1dm5gdjhCihrJnBNLrippecGA4AZzbD8uGAAruW0uGfwumb5rOhpMbmNVtFne3udvsCG3a+u955qw5QJ/W9XjsxtZmhyOEqMHsqWqbYfXYDegG7AD6VEhE1dWZv4wm005uMHoN6XWCeXTT/7Hx5EYe7/Y4d7W5y+wIbYo8n8zET3bSLMCT+Xd0wlFasAkhKpA9VW23WD9XSgUBb1RYRNVR1A5YPgxcfWD0t6T7NmHaxmlsjtrM7O6zGdl6pNkR2pSQmsG4ZREoBYtHh+Pt5mx2SEKIGq4s7WSjgDblHUi1deJ3WH4bePrD6DWkeddn2q9T+e3UbzzV4ylub3W72RHalJWteWTFLiLPJ7Ps/m409fc0OyQhRC1gzzWetzB6KwCj+XUnjB4MxLHf4NOR4NPQSDqe/kz5dQpbTm3hmaue4baWt5kdYbFe/vEgGw/F8PzQ9lzdPMDscIQQtYQ9JZ4Iq8eZwAqt9ZYKiqf6OLIBVtwFdZrCvd+S6u7LlA2PsO30NuZePZdhVwwzO8JifRFxkoWbj3LvVU0Z1UM6GxdCVB57Es8qIFVrnQWglHJUSnlorS9VbGhV2D/r4PN7IKAl3LuaFFdPHtkwmT/O/MHcnnMZ2mKo2REWa8fxizz59T56tvDnqUFtzQ5HCFHL2NVzAWB9+7o78EvFhFMN/L0GPrsb6rWB0d9yycWDyeuNpPP8Nc9X+aRzKi6FBz7eQSM/N965qwvOjvYcAkIIUX7sKfG4WQ93rbVOUkp5VGBMVde+L+HL8dC4C4z6kkuOzjy84WF2nNvBC9e8wC3Nbyl5HSZKTstk3EcRpGVk89mEcPw8XMwOSQhRC9nzczdZKdUl54lSqitQMwb+Lo2/PoMvx0FQd7jnay45OjNp/SR2nNvBi9e8WOWTTna25tGVf3HobAJv3tWZFvWkQwohhDnsKfFMBb5QSp3G6KetAcZQ2LXHzmXw7SMQei3c+RnJCib9MpG/Yv7i5Wtf5sbQG82OsERvrD/Mj/vPMntgG65vVc/scIQQtZg9N5BuV0q1BnIG+z6ktc6o2LCqkD8XwffTocUNMHI5STqLiT9PZO/5vbx83csMCBlgdoQl+m7Pad5cf5gRXZtw/zWhZocjhKjlSqxqU0o9BHhqrfdprfcBXkqpSRUfWhWw7V0j6bS6Ge74lESdyYO/PMi+8/t4pdcr1SLp7I2KZ/oXf9G1aR2eH9YeGd1CCGE2e67xjLeMQAqA1joWGF9xIVUR/3sd1j0ObYfAiI9IzE7nwZ8fZP/5/bza61X6Ne1ndoQlik5IZfyyCPw9XXl/VFdcnRzNDkkIIey6xuOolFJaaw3GfTxAzW0OpTVs+g9sfBE6jICh75OQdYkHfnqAg7EHea33a/QJrvr9o6ZmZDH+4x3Ep2Tw5cSrCfR2NTskIYQA7Es8PwKfK6UWWJ4/YJlW82gNG56D316DTnfD4LeIz0jigZ8f4J/Yf3i99+v0DuptdpQl0lrz+Fd7+etkHO+P6krbRjJmnxCi6rAn8cwEJgATLc9/BhZVWERm0Rp+mg3b3oauY2Dgf4nPSGT8T+P5N+5f3rj+Da5rUuTQRFXO+5uO8vWuUzzaryU3tm9gdjhCCJFPidd4tNbZWuv3tda3aa1vAw4Ab1V8aJUoOxu+n2Ekne4PwqDXiUtPYNxP4zgSd4Q3+7xZbZLOLwfO8Z91BxnUsSEP92lhdjhCCFGIXcMiKKU6A3cCtwPHgK8qMqhKlZ0N300x7tW5+hHoN5fYtDjG/zSeyIRI3uzzJj0b9zQ7SrscOpvIlM920b6RL6/cFiYt2IQQVZLNxKOUaomRbO4EzgOfA0prfX0lxVbxsrPgm4fgrxVw3Qy4/kkupsUy7qdxnEg4wZt93uTqRlebHaVdLianc/9H2/F0dWLRveG4u0gLNiFE1VRciecg8BswSGv9L4BSalqlRFUZsjLg6weM/teunw29ZnAh5QLjfhpHVGIUb/d9mx4Ne5gdpV3SM7OZuHwH0YlprHzgKhr4upkdkhBC2FTcNZ7hwBngV6XUIqVUX4wuc6q/zHRYNcZIOv3mQq8ZnE85z/3r7udU0ine6ftOtUk6Wmue+XYffxy7yH9u7UinID+zQxJCiGLZTDxa69Va6zuA1sCvGH221VNKvaeU6l9ZAZa7jFRYeY8xvMGNL0PPKcRcimHsurGcTj7NO33foVvDbmZHabePtkay4s+TTOrdnKGdG5sdjhBClMieVm3JWutPtda3AE2AXRhNrKuf9Evw2Z3wz48w6HXo8SDRl6IZu24sZ5PP8t4N73FlgyvNjtJuvx2O4bm1f3NDm/pM79+q5AWEEKIKKNUoYFrrWK31Qq1138vZqFJqmlJqv1Jqn1JqhVKq4i9KpCfDp7fDkV9hyDsQPpZzyecYu24s0ZeiWdBvAV3rd63wMMrL0ZgkHvpkJy0CvXjjjk44ONSMWlAhRM1X6cNPKqUaA48A4Vrr9oAjcEeFbjQ1AZbfCse3wvBF0HkUZ5PPMnbdWM6nnGdBvwV0rte5QkMoT/EpGYz7KAInRwcWjw7Hy9WuVvFCCFElmHXGcgLclVIZgAdwuty3sGclrJ8L8VHg6Gy0YhvxIbQbmpt0YlNjWdBvAWGBYeW++YqSmZXN5BW7OHHxEp+M605Q3do5GKwQovqq9BKP1voU8CpwAqPVXLzW+qeC8ymlJiilIpRSETExMaXbyJ6VsOYRiD8JaMhKtySfdE4nnea+H+8jLjWOhf0WVqukA/Di9wfZ/E8Mzw9tT/dm/maHI4QQpWZGVVsdYAgQCjQCPJVSowrOZ7mWFK61Dg8MDCzdRtbPhYwCo3NnpXPq17mMXTeWhPQEFvVfRIfADmV9G6b4fPsJlmw5xn1Xh3BHt2CzwxFCiDKp9MQD3AAc01rHWEYy/Qoo3+4B4qMKTYpycmSMVxaJ6Yks6r+IdgHtynWTFe3PYxeZvXof114RwOyBbcwORwghysyMazwngB5KKQ8gBegLRJTrFnybsDbzAvPr+HHWyZHArCxSlUIpBxb3X0wb/+p14j558RIPLt9BUB0P3r6zC06OZvxeEEKI8mHGNZ4/gFXATmCvJYaF5bmNtZ2HMSfAnzPOTmiliHZyIsHBgdGN+lS7pJOclsn4ZRFkZGWzaHQ4vh7OZockhBCXxZSfzlrrZ7TWrbXW7bXW92it08pz/fPP/0FqwftalOKLxIPluZkKl52tmfr5bv45l8g7d3WheaCX2SEJIcRlq5F1NmeTz5ZqelX135//4ecD55g9sC3XtSxlAwshhKiiamTiaeBZ9KibtqZXRd/sPsXbv/7LHVcGMaZniNnhCCFEuamRiWdKlym4OebvhcfN0Y0pXaaYFFHp/HUyjsdW7aFbSF3mDmkvA7oJIWqUGtnXysBmAwGYv3M+Z5PP0sCzAVO6TMmdXpWdjU9l/LIIAr1deW9UF1ycauRvAyFELVYjEw8Yyac6JBprqRlZTPg4guS0TJbdfzX+Xq5mhySEEOWuxiae6kZrzYxVe9h7Kp6F94TTuoGP2SEJIUSFkHqcKuLdjUdY89dppvdvRb+29c0ORwghKowknipg3f6zvLLuEEM6NWJS7+ZmhyOEEBVKEo/J/j6TwLTPdxPWxJeXb+0oLdiEEDWeJB4TnU9KY9xHEXi7ObHw3nDcnB3NDkkIISqcNC4wSXpmNhOX7+B8UhpfPHgV9X0qfvRvIYSoCiTxmEBrzezVe9keGctbd3amYxM/s0MSQohKI1VtJliyJZKVEVFM7tOCW8IamR2OEEJUKkk8lWzTPzG8sPYAA9rVZ9oNLc0ORwghKp0knkr0b3QSD3+6k5b1vfnv7Z1wKDh0gxBC1AKSeCpJ/KUMxi+LwMXRgcWjw/F0lctrQojaSc5+lSAzK5uHPt1JVOwlVozvQZM6HmaHJKqhjIwMoqKiSE1NNTsUUcW4ubnRpEkTnJ2rxwjFkngqwfNr/+Z//57nP7d2JDykrtnhiGoqKioKb29vQkJC5EZjkUtrzYULF4iKiiI0NNTscOwiVW0V7NM/TvDh1kjGXRPK7VcGmR2OqMZSU1Px9/eXpCPyUUrh7+9frUrCkngq0O9HL/D0N/vo1TKQx29uY3Y4ogaQpCOKUt2OC0k8FeTEhUtMXL6Dpv4evHVXZxylBZsQQgCSeCpEYmoG45ZtJ1vD4tFX4uNWPS74iZpl9a5T9Jy3gdBZa+k5bwOrd50yO6QKExcXx7vvvpv7/PTp09x2220mRiSKI4mnnGVla6Z+tpsjMcm8e3cXQgM8zQ5J1EKrd53i8a/2ciouBQ2cikvh8a/21tjkUzDxNGrUiFWrVpkYUdEyMzPNDqFKkMRTzl5Zd4j1B6N55pa29GwRYHY4ooZ6ds1+Ri7YZvPvsVV7SMnIyrdMSkYWj63aY3OZZ9fsL3abycnJDBw4kLCwMNq3b8/nn38OwI4dO+jVqxddu3ZlwIABnDlzBoDevXszbdo0wsPDadOmDdu3b2f48OFcccUVzJ49O3e9Q4cOpWvXrrRr146FCxfmTvfy8uLJJ58kLCyMHj16cO7cOQDOnTvHsGHDCAsLIywsjK1btzJr1iyOHDlCp06dmDFjBpGRkbRv3x6ArKwspk+fTvv27enYsSNvvfVWofe2aNEirrzySsLCwrj11lu5dOmSzW0BLFu2jI4dOxIWFsY999wDwH333Zcv2Xl5eQGwceNGrr32WgYPHkzbtm2Lfc8//vgjXbp0ISwsjL59+5Kdnc0VV1xBTEwMANnZ2bRo0SL3eXUlzanL0de7onh/0xHu6h7MPT2amh2OqMXSs7JLNd0eP/74I40aNWLt2rUAxMfHk5GRweTJk/nmm28IDAzk888/58knn2TJkiUAuLi4EBERwfz58xkyZAg7duygbt26NG/enGnTpuHv78+SJUuoW7cuKSkpXHnlldx66634+/uTnJxMjx49eOGFF3jsscdYtGgRs2fP5pFHHqFXr158/fXXZGVlkZSUxLx589i3bx+7d+8GIDIyMjfuhQsXEhkZye7du3FycuLixYuF3tvw4cMZP348ALNnz+aDDz5g8uTJRW5r//79PP/882zdupWAgIAi11fQzp072bdvX25z56Lec3Z2NuPHj2fz5s2EhoZy8eJFHBwcGDVqFJ988glTp07ll19+ISwsjMDAwDJ/jlWBJJ5ysvNELDO/3EuPZnV5dnC7atfKRFQvz9zSrtjXe87bwKm4lELTG/u58/kDV5Vpmx06dODRRx9l5syZDBo0iGuvvZZ9+/axb98++vXrBxili4YNG+YuM3jw4Nxl27Vrl/tas2bNOHnyJP7+/rz55pt8/fXXAJw8eZLDhw/j7++Pi4sLgwYNAqBr1678/PPPAGzYsIFly5YB4OjoiK+vL7GxsTbj/uWXX3jwwQdxcjJOd3XrFr6Xbt++fcyePZu4uDiSkpIYMGCAzW0tW7aMESNGEBAQYHN9BXXr1i3fPTZFveeYmBiuu+663Ply1jt27FiGDBnC1KlTWbJkCWPGjClxe1WdJJ5ycCY+hQnLdtDAx4337u6Ks6PUYApzzRjQise/2puvus3d2ZEZA1qVeZ0tW7Zk586dfP/998yePZu+ffsybNgw2rVrx7Zt24pcxtXVFQAHB4fcxznPMzMz2bhxI7/88gvbtm3Dw8OD3r17596P4uzsnPsDztHRsUKvj9x3332sXr2asLAwPvzwQzZu3FjqdTg5OZGdbZQos7OzSU9Pz33N0zPvWm9x77koQUFB1K9fnw0bNvDnn3/yySeflDq2qkbOkJcpJT2L8csiSM3IYvHocOp4upgdkhAM7dyYl4Z3oLGfOwqjpPPS8A4M7dy4zOs8ffo0Hh4ejBo1ihkzZrBz505atWpFTExMbuLJyMhg//7irxVZi4+Pp06dOnh4eHDw4EF+//33Epfp27cv7733HmCUsOLj4/H29iYxMbHI+fv168eCBQtyE1dRVWOJiYk0bNiQjIyMfCf2orbVp08fvvjiCy5cuJBvfSEhIezYsQOAb7/9loyMjFK95x49erB582aOHTtWKM5x48YxatQoRowYgaNj9R+pWBLPZdBaM/2Lv9h/OoH5d3SiZX1vs0MSItfQzo3ZMqsPx+YNZMusPpeVdAD27t1Lt27d6NSpE88++yyzZ8/GxcWFVatWMXPmTMLCwujUqVPuBXh73HjjjWRmZtKmTRtmzZpFjx49Slxm/vz5/Prrr3To0IGuXbty4MAB/P396dmzJ+3bt2fGjBn55h83bhzBwcG5jQE+/fTTQut87rnn6N69Oz179qR169bFbqtdu3Y8+eST9OrVi7CwMP7v//4PgPHjx7Np0ybCwsLYtm1bvlKOPe85MDCQhQsXMnz4cMLCwhg5cmTuMoMHDyYpKalGVLMBKK212TGUKDw8XEdERJgdRiHzfznM67/8w+M3teaBXs3NDkfUcH///Tdt2kgPGLVRREQE06ZN47fffrM5T1HHh1Jqh9Y6vKLjKy25xlNGP+w9w+u//MPwzo2ZcF0zs8MRQtRQ8+bN47333qsR13ZySFVbGew/Hc//rfyLzsF+vDi8g7RgE0JUmFmzZnH8+HGuueYas0MpN5J4SikmMY3xH0Xg5+HMgnu64uZc/S/0CSFEZZKqtlJIy8zigY8juHgpnVUPXk09bzezQxJCiGpHEo+dtNY88dU+dp6I4527utC+sa/ZIQkhRLUkVW12WvzbMb7cGcWUvlcwsGPDkhcQQghRJEk8dvj1YDQv/vA3N3dowJS+V5gdjhD22bMSXm8Pc/yM/3tWmh0RAKtXr+bAgQNlWlaGP6gZJPGU4PC5RCav2EXbhj68OiIMBxnQTVQHe1bCmkcg/iSgjf9rHqkSyac8E48Mf1A9SeIpRmxyOuOWReDm7Miie8PxcJFLYqKK+GEWLB1o+++bhyGjQCehGSnGdFvL/DCr2E0WNSzChg0bGDp0aO48P//8M8OGDQOKHtZg69atfPvtt8yYMYNOnTpx5MiRUg1JIMMf1AymnEmVUn7AYqA9oIGxWuuiexk0SUZWNpM+2cmZuFRWTOhBIz93s0MSwn5ZaaWbboeihkXw8fFh0qRJxMTEEBgYyNKlSxk7diyAzWENBg8ezKBBg3KryPz8/OwekkCGP6gZzPoJPx/4UWt9m1LKBfAwKQ6b5q45wLajF3htRBhdm9YxOxwh8rtpXvGvv97eUs1WgG8QjFlbpk0WNSwCwD333MPy5csZM2YM27Ztyx1GwNawBgWVZkgCGf6gZqj0qjallC9wHfABgNY6XWsdV9lxFOfjbZF8/PtxHriuGbd2bWJ2OEKUXt+nuui/pQAAEK5JREFUwblAKd3Z3ZheRjnDInTo0IHZs2czd+5cAMaMGcPy5ctZsWIFI0aMyD3x2zuswX333cfbb7/N3r17eeaZZ4odIuBylce2yjL8wV9//UXnzp1LNfzBTTfdVOrYqgszrvGEAjHAUqXULqXUYqVUoW5clVITlFIRSqmIyqzn3PrveeasOUCf1vV47MbWJS8gRFXU8Xa45U2jhIMy/t/ypjG9jIoaFgGMC/yNGjXi+eeft+tXesEhDEozJIEMf1AzmJF4nIAuwHta685AMlDoqqbWeqHWOlxrHV5Z9ZyR55OZ+MlOmgV4Mv+OTjhKCzZRnXW8Habtgzlxxv/LSDpQ9LAIOe6++26CgoLs6j37jjvu4JVXXqFz584cOXKkVEMSyPAHNUOlD4uglGoA/K61DrE8vxaYpbUeaGuZyhgWISE1g+HvbuV8UhrfPNSTpv5FH0xCmKUqD4vw8MMP07lzZ+6//36zQ6nW7Bn+wBYZFqEYWuuzSqmTSqlWWutDQF+gbI36y0lWtmbKil1Enk9m2f3dJOkIUQpdu3bF09OT1157zexQqrWaOPyBLWa1apsMfGJp0XYUMLVc+fKPB/n1UAzPD23P1c0DzAxFiGon53qHuDyzZs1i1qzi76WqKUxJPFrr3UCVKP6t2hHFws1Hufeqpozq0dTscIQQosar1T0X7Dh+kSe+2svVzf15alBbs8MRQohaodYmnlNxKTzw8Q4a+rnx7t1dcHastbtCCCEqVa3sfOxSeibjPoogLSObzyaE4+fhYnZIQghRa9S6n/nZ2ZpHV/7FobMJvHlXZ1rU8zY7JCEqxNqja+m/qj8dP+pI/1X9WXu0bF3lmKl3797k3EoREhLC+fPnTY5IlIdaV+J5Y/1hfth3ltkD23B9q3pmhyNEhVh7dC1zts4hNcvoouVM8hnmbJ0DwMBmNm+Zq3Raa7TWODhU/d/AmZmZud0BictTq/bid3tO8+b6w4zo2oT7rwkteQEhqqiX/3yZgxcP2nx9T8we0rPT801LzUrl6S1Ps+qfosevaV23NTO7zSx2u//9739ZsmQJYPQUMHXqVGbNmkVQUBAPPfQQAHPmzMHLy4vp06fzyiuvsHLlStLS0hg2bBjPPvsskZGRDBgwgO7du7Njxw6+//575s2bx/bt20lJSeG2227j2WeftXtfTJw4schlt2/fzpQpU0hOTsbV1ZX169fj4eHBzJkz+fHHH3FwcGD8+PFMnjyZkJAQIiIiCAgIICIigunTp7Nx40bmzJnDkSNHOHr0KMHBwbz00kvcc889JCcnA/D2229z9dVXA/Dyyy+zfPlyHBwcuOmmmxg/fjwjRozI7Vro8OHDjBw5Mvd5bVZrEs/eqHimf/EXXZvW4flh7XM7LxSiJiqYdEqabo8dO3awdOlS/vjjD7TWdO/enV69ejFy5EimTp2am3hWrlzJunXr+Omnnzh8+DB//vknWmsGDx7M5s2bCQ4O5vDhw3z00Ue53ci88MIL1K1bl6ysLPr27cuePXv+v727D47qOu84/v1ZCFYIW4DAjIywDY1HTHAA8VYTgoeQVFLBQwqEEKZpiwvYtYtN0o49YTIuMJ56kpqxg9tOEk9stbYTW1PZggwJBhynKbgtL47Fe0BxIAlCIA0uYF7iCPH0j3skFoGMePHeq/XzmdnR7tndu7+9uqtH99y75zB8+PBO5brUc4cOHcrs2bOpqqpi7NixnDhxgry8vE5NndDe7t272bhxI3l5eZw+fZr169eTSqWoq6tjzpw5bN26lTVr1rBq1So2bdpEz549ee+99+jbty8FBQXU1tYycuRIKisrs34onM76WBSexhO/Z8ELWynM78F3vzKaHt2yd/A99/FwuT2TsuoyGk41XNRelF9EZUXlVb3mxo0bmT59etvYZDNmzGDDhg08/PDDNDY2cujQIZqamujTpw+DBg1ixYoVrFu3jtLSUgBOnjxJXV0dt956K7fddltb0YGoWD377LOcPXuWhoYGdu/e3enCc6nnSqKoqIixY8cCcNNNNwGdmzqhvWnTppGXF4303dzczMKFC6mtrSUnJ4d9+/a1Lffee++lZ8+eFyx3/vz5VFZW8tRTT1FVVcXmzZs79Z6yXdYWnpXv1PPk2r0cOnaGbjkCg5ULJ9D/xh5xR3PuI7do1KILjvEApHJSLBq16CN5vVmzZlFdXc3hw4fbBr00MxYvXsz9999/wWMPHDhwwcCa+/fvZ/ny5WzZsoU+ffowd+7cTk9XcC3PTZc+1UH756dnffrppxkwYADbtm3j3LlzpFKpD13uzJkzWbZsGZMnT2b06NEUFhZecbZslPwjeldh5Tv1LH5tB/XHzmBAc4shQd2Rk3FHcy4jpg6ZytJPL6UovwghivKLWPrppdd0YsHEiRNZuXIlp0+f5tSpU9TU1LRNBjd79mxeeeUVqqurmTVrFgDl5eU8//zznDwZfe7q6+tpbGy8aLknTpwgPz+fgoICjhw5wpo1azqdqaPnlpSU0NDQwJYtW4BoOoSzZ892OHVC+lQHr776aoevd/z4cYqKirjhhht48cUXaWlpAaIpGSorK9um0m5dbiqVory8nAceeMC72dJk5R7Pk2v3cqa55YK2P7QYT67dy5+VDowplXOZNXXI1Ot6BtuoUaOYO3cu48aNA6JupNZutGHDhvH+++8zcOBAioqKACgrK2PPnj2MHz8egF69evHSSy9dNM/MiBEjKC0tZejQoQwaNIgJEyZ0OlNHz+3evTtVVVU89NBDnDlzhry8PN544w3mz5/Pvn37GD58OLm5uSxYsICFCxeyZMkS5s2bx2OPPcakSZM6fL0HH3yQmTNn8sILL1BRUdG2N1RRUUFtbS1jxoyhe/fuTJkyhSeeeAKIpoyoqamhrKys0+8r22V8WoSrcaXTIgz++o+51LsSsP+byTmV1LkrkeRpEVzHli9fzvHjx3n88cc/0tfxaRFidkvvPOqPnblku3POZcr06dN59913efPNN+OOkihZeYznkfIS8nIv3J3Py83hkfKSmBI55z6Oampq2L59O/36+XQr6bJyj6f1OE7rWW239M7jkfISP77jujwz8++guYt0hUMm6bKy8EBUfLzQuGySSqU4evQohYWFXnxcGzPj6NGjlz21O0mytvA4l22Ki4s5ePAgTU1NcUdxCZNKpSguLo47Rqd54XGui8jNzWXwYB9j0HV9WXlygXPOueTywuOccy6jvPA455zLqC4xcoGkJuA3cecI+gFJnwbRM167pOeD5GdMej7I/oy3mVn/6xnmeugShSdJJG1N4hAU6TzjtUt6Pkh+xqTnA88YF+9qc845l1FeeJxzzmWUF54r92zcATrBM167pOeD5GdMej7wjLHwYzzOOecyyvd4nHPOZZQXHueccxnlhedDSEpJ2ixpm6RdkpaF9sGSNkn6laQqSd1jzpkj6R1JqxOa74CkHZJqJW0NbX0lrZdUF372iTljb0nVkn4paY+k8UnJKKkkrLvWywlJX01KvrScXwufk52SXg6fn8Rsi5IWhWy7JH01tMW6DiU9L6lR0s60tktmUuSZsC63SxqVyazXkxeeD/cBMNnMRgAjgQpJdwHfAp42s08A/wfMizEjwCJgT9rtpOUD+KyZjUz7PsLXgZ+a2R3AT8PtOK0AXjezocAIovWZiIxmtjesu5HAaOA0UJOUfACSBgIPA2PM7E4gB/gyCdkWJd0JLADGEf1+75H0CeJfh/8GVLRr6yjTnwJ3hMt9wHcylPH6MzO/dOIC9AR+Afwx0beIu4X28cDaGHMVE22ck4HVgJKUL2Q4APRr17YXKArXi4C9MeYrAPYTTrZJYsa0TGXAW0nLBwwEfgf0JRr1fjVQnpRtEZgFPJd2+zHg0SSsQ+B2YOfltjvge8CcSz2uq118j+cyQjdWLdAIrAfeBY6Z2dnwkINEH7q4fJvoA3Qu3C4kWfkADFgn6W1J94W2AWbWEK4fBgbEEw2AwUATUBm6LL8vKZ9kZWz1ZeDlcD0x+cysHlgO/BZoAI4Db5OcbXEnMFFSoaSewBRgEAlah2k6ytRa3Fsl4bN9VbzwXIaZtVjUxVFMtJs+NOZIbSTdAzSa2dtxZ7mMz5jZKKKugr+VdHf6nRb9+xbnef3dgFHAd8ysFDhFuy6XBGQkHB+ZBvxH+/vizheOQ3yBqIjfAuRzcRdSbMxsD1G33zrgdaAWaGn3mNh/x+0lMdP14IWnk8zsGPAzou6C3pJaJ9ErBupjijUBmCbpAPAKUXfbCpKTD2j7bxgzayQ6NjEOOCKpCCD8bIwvIQeBg2a2KdyuJipEScoIUeH+hZkdCbeTlO/zwH4zazKzZuA1ou0zMduimT1nZqPN7G6i4037SNY6bNVRpnqivbRWsX+2r5YXng8hqb+k3uF6HvAnRAedfwZ8MTzsr4BVceQzs8VmVmxmtxN1wbxpZn+elHwAkvIl3dh6negYxU7gRyEbxJzRzA4Dv5NUEpo+B+wmQRmDOZzvZoNk5fstcJeknpLE+XWYpG3x5vDzVmAG8EOStQ5bdZTpR8BfhrPb7gKOp3XJdS1xH2RK8gUYDrwDbCf6Y/kPoX0IsBn4FVG3R48EZJ0ErE5avpBlW7jsAr4R2guJToqoA94A+sa8/kYCW8PveiXQJ0kZibqujgIFaW2JyRfyLAN+GT4rLwI9ErYtbiAqhtuAzyVhHRL9I9EANBPtec/rKBPRiUP/SnSceQfRGYSx/b6v5eJD5jjnnMso72pzzjmXUV54nHPOZZQXHueccxnlhcc551xGeeFxzjmXUV54XFaR1BJGcN6laFTxv5d0Q7hvjKRnYsr133G8rnNJ5KdTu6wi6aSZ9QrXbyb6kuBbZrYk3mTOuVa+x+OylkVD9NwHLAzf9p6k83MWLZX075I2SPqNpBmS/knRvEGvS8oNjxst6edhgNO1aUOZ/Kekbymar2mfpImhfVhoqw1zptwR2k+Gn5L0ZJgXZoek2aF9Ulhm65xAPwgjACDpm5J2h+Utz/R6dO5663b5hzjXdZnZryXlADdf4u4/Aj4LfBL4H2CmmT0qqQaYKunHwD8DXzCzplAk/hH46/D8bmY2TtIUYAnReGV/A6wwsx+EQT1z2r3mDKJREkYA/YAtkv4r3FcKDAMOAW8BEyTtAaYDQ83MWodwcq4r88LjPs7WmFmzpB1EBeL10L6DaI6UEuBOYH3Y+cghGt6k1Wvh59vh8RAVsG9IKgZeM7O6dq/5GeBlM2shGgzy58BY4ASw2cwOAoSpOG4H/hf4PfBc2Ftbfe1v27l4eVeby2qShhANf3+pUYc/ADCzc0CznT/geY7onzIBuyzM/mlmnzKzsvbPD8vvFpb1Q6KpC84AP5E0+QrifpB2vYVoj+os0Wje1cA9nC+OznVZXnhc1pLUH/gu8C92dWfR7AX6SxoflpcradhlXnMI8Gsze4ZoVOHh7R6yAZitaILB/sDdRINodrS8XkQDg/4E+BpRF51zXZp3tblskxe6qXKBs0SjJD91NQsysz9I+iLwjKQCos/Lt4lG2e7Il4C/kNRMNHvkE+3uryGa02kb0QRfj5rZYUkdTTB4I7BKUopoD+zvrua9OJckfjq1c865jPKuNueccxnlhcc551xGeeFxzjmXUV54nHPOZZQXHueccxnlhcc551xGeeFxzjmXUf8PwnSG1eGoqKkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEW1zMgVMREr"
      },
      "source": [
        "## 4.2. Performance Evaluation with Data Processing Techiques\n",
        "\n",
        "\n",
        "You are required to evaluate with the testing dataset and provide the table with f1 of test set.\n",
        "Note that it will not be marked if you do not display it in the ipynb file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVCF0bwTtRS0"
      },
      "source": [
        "(*Please show your empirical evidence and justification*)\n",
        "\n",
        "Empirical evidence:\n",
        "See output of below code cell.\n",
        "\n",
        "Explanation & Justification:\n",
        "1. Trend from tables = The f1 scores were better for without URL (3rd table) than for with URL (4th table). So, having no URL is better, as it is not the main part of each post, and also may contain irrelevant special characters like /.  \n",
        "2. Trend from tables = The f1 scores were better for without stopwords (1st table) than for with stopwords (2nd table). Stopwords are highly common words (for e.g. prepositions) that do not add much meaning to posts, so not having them is better.\n",
        "3. Hence, both URL and stopwords have been removed when processing data in relevant sections.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPHCb-bneTI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba08579-ad3c-498d-f426-c7f6dddbef49"
      },
      "source": [
        "# without URL. punctuation, numbers & stopwords removed. all lowercase\n",
        "import re \n",
        "\n",
        "# method for removing url and doing some basic cleaning/formatting for better experience later\n",
        "def url_remover(tx):\n",
        "    # escape the pipe separators\n",
        "    regex = re.compile('[%s]' % re.escape('|'))\n",
        "    tx = regex.sub(' ',tx)\n",
        "    # deal with words individually and remove those with http (i.e. url)\n",
        "    ws = str(tx).split()\n",
        "    ws = [x for x in ws if not 'http' in x]\n",
        "    # join the words when done, then return them\n",
        "    ws = ' '.join(ws)\n",
        "    return ws\n",
        "\n",
        "# apply the above method\n",
        "testing_posts1 = testing_data['posts'].apply(url_remover)\n",
        "# need re as earlier\n",
        "import re\n",
        "# remove punctuations and numbers, go lowercase \n",
        "def pln(x):\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    x = re.sub('^\\d+\\s|\\s\\d+\\s|\\s\\d+$','',x)\n",
        "    x = x.lower()\n",
        "    return x\n",
        "testing_posts1 = testing_posts1.apply(pln)\n",
        "\n",
        "# now, remove stopwords - need nltk for this\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.tokenize import word_tokenize\n",
        "def stopper(x):\n",
        "    tokens = word_tokenize(x)\n",
        "    stop_words = sw.words()\n",
        "    x = [w for w in tokens if not w in stop_words]\n",
        "    return x \n",
        "testing_posts1 = testing_posts1.apply(stopper)\n",
        "\n",
        "testing_encoded1 = encode_and_add_padding(testing_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(testing_labels)\n",
        "label_encoded= lEnc.transform(testing_labels)\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn #ignore irrelavant warnings that came up\n",
        "\n",
        "# start evaluation\n",
        "model1.eval()\n",
        "outputs = model1(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded, predicted.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "# without URL. punctuation & numbers removed. all lowercase\n",
        "import re \n",
        "\n",
        "# method for removing url and doing some basic cleaning/formatting for better experience later\n",
        "def url_remover(tx):\n",
        "    # escape the pipe separators\n",
        "    regex = re.compile('[%s]' % re.escape('|'))\n",
        "    tx = regex.sub(' ',tx)\n",
        "    # deal with words individually and remove those with http (i.e. url)\n",
        "    ws = str(tx).split()\n",
        "    ws = [x for x in ws if not 'http' in x]\n",
        "    # join the words when done, then return them\n",
        "    ws = ' '.join(ws)\n",
        "    return ws\n",
        "\n",
        "# apply the above method\n",
        "testing_posts2 = testing_data['posts'].apply(url_remover)\n",
        "training_posts2 = training_data['posts'].apply(url_remover)\n",
        "# need re as earlier\n",
        "import re\n",
        "# remove punctuations and numbers, go lowercase \n",
        "def pln(x):\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    x = re.sub('^\\d+\\s|\\s\\d+\\s|\\s\\d+$','',x)\n",
        "    x = x.lower()\n",
        "    return x\n",
        "testing_posts2 = testing_posts2.apply(pln)\n",
        "training_posts2 = training_posts2.apply(pln)\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_cbow_model2 = Word2Vec(sentences=training_posts2, size=100, window=3, min_count=5, workers=2, sg=0)\n",
        "\n",
        "word_set_train = set() \n",
        "for sent in training_posts2:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "import gensim.downloader as api\n",
        "word_emb_model1 = api.load(\"glove-twitter-25\")\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_cbow_model2.vector_size+word_emb_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model1 and word in wv_cbow_model2:\n",
        "        emb_table.append(np.concatenate((wv_cbow_model2[word],word_emb_model1[word]),0))\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded2 = encode_and_add_padding(training_posts2, seq_length, word_index_train)\n",
        "testing_encoded2 = encode_and_add_padding(testing_posts2, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded2= lEnc.transform(training_labels)\n",
        "\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model2 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model2.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded2)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded2)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model2.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model2(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model2.eval()\n",
        "outputs2 = model2(torch.from_numpy(np.array(testing_encoded2)).to(device)) \n",
        "predicted2 = torch.argmax(outputs2, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded, predicted2.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "# without URL. punctuation removed. all lowercase\n",
        "import re \n",
        "\n",
        "# method for removing URL & doing some basic cleaning/formatting for better experience later\n",
        "def remover(tx):\n",
        "    # escape the pipe separators\n",
        "    regex = re.compile('[%s]' % re.escape('|'))\n",
        "    tx = regex.sub(' ',tx)\n",
        "    # deal with words individually\n",
        "    ws = str(tx).split()\n",
        "    ws = [x for x in ws if not 'http' in x]\n",
        "    # join the words when done, then return them\n",
        "    ws = ' '.join(ws)\n",
        "    return ws\n",
        "\n",
        "# apply the above method\n",
        "testing_posts3 = testing_data['posts'].apply(remover)\n",
        "training_posts3 = training_data['posts'].apply(remover)\n",
        "# need re as earlier\n",
        "import re\n",
        "# remove punctuations, go lowercase \n",
        "def pln(x):\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    x = x.lower()\n",
        "    return x\n",
        "testing_posts3 = testing_posts3.apply(pln)\n",
        "training_posts3 = training_posts3.apply(pln)\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_cbow_model2 = Word2Vec(sentences=training_posts3, size=100, window=3, min_count=5, workers=2, sg=0)\n",
        "\n",
        "word_set_train = set() \n",
        "for sent in training_posts3:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "\n",
        "import gensim.downloader as api\n",
        "word_emb_model1 = api.load(\"glove-twitter-25\")\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_cbow_model2.vector_size+word_emb_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model1 and word in wv_cbow_model2:\n",
        "        emb_table.append(np.concatenate((wv_cbow_model2[word],word_emb_model1[word]),0))\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded3 = encode_and_add_padding(training_posts3, seq_length, word_index_train)\n",
        "testing_encoded3 = encode_and_add_padding(testing_posts3, seq_length, word_index_train)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded3= lEnc.transform(training_labels)\n",
        "\n",
        "\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model3 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model3.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded3)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded3)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model3.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model3(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "model3.eval()\n",
        "outputs3 = model3(torch.from_numpy(np.array(testing_encoded3)).to(device)) \n",
        "predicted3 = torch.argmax(outputs3, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded, predicted3.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "# with URL. punctuation removed. all lowercase\n",
        "import re \n",
        "\n",
        "# method for doing some basic cleaning/formatting for better experience later\n",
        "def remover(tx):\n",
        "    # escape the pipe separators\n",
        "    regex = re.compile('[%s]' % re.escape('|'))\n",
        "    tx = regex.sub(' ',tx)\n",
        "    # deal with words individually\n",
        "    ws = str(tx).split()\n",
        "    # join the words when done, then return them\n",
        "    ws = ' '.join(ws)\n",
        "    return ws\n",
        "\n",
        "# apply the above method\n",
        "testing_posts4 = testing_data['posts'].apply(remover)\n",
        "training_posts4 = training_data['posts'].apply(remover)\n",
        "# need re as earlier\n",
        "import re\n",
        "# remove punctuations, go lowercase \n",
        "def pln(x):\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    x = x.lower()\n",
        "    return x\n",
        "testing_posts4 = testing_posts4.apply(pln)\n",
        "training_posts4 = training_posts4.apply(pln)\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_cbow_model2 = Word2Vec(sentences=training_posts4, size=100, window=3, min_count=5, workers=2, sg=0)\n",
        "\n",
        "word_set_train = set() \n",
        "for sent in training_posts4:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "import gensim.downloader as api\n",
        "word_emb_model1 = api.load(\"glove-twitter-25\")\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_cbow_model2.vector_size+word_emb_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model1 and word in wv_cbow_model2:\n",
        "        emb_table.append(np.concatenate((wv_cbow_model2[word],word_emb_model1[word]),0))\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded4 = encode_and_add_padding(training_posts4, seq_length, word_index_train)\n",
        "testing_encoded4 = encode_and_add_padding(testing_posts4, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded4= lEnc.transform(training_labels)\n",
        "\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model4 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model4.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded4)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded4)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model4.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model4(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "model4.eval()\n",
        "outputs4 = model4(torch.from_numpy(np.array(testing_encoded4)).to(device)) \n",
        "predicted4 = torch.argmax(outputs4, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded, predicted4.cpu().numpy(),digits=4))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6141    0.6167    0.6154       467\n",
            "           1     0.5503    0.5475    0.5489       400\n",
            "\n",
            "    accuracy                         0.5848       867\n",
            "   macro avg     0.5822    0.5821    0.5821       867\n",
            "weighted avg     0.5846    0.5848    0.5847       867\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5352    0.8951    0.6699       467\n",
            "           1     0.4302    0.0925    0.1523       400\n",
            "\n",
            "    accuracy                         0.5248       867\n",
            "   macro avg     0.4827    0.4938    0.4111       867\n",
            "weighted avg     0.4868    0.5248    0.4311       867\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5435    0.8158    0.6524       467\n",
            "           1     0.4819    0.2000    0.2827       400\n",
            "\n",
            "    accuracy                         0.5317       867\n",
            "   macro avg     0.5127    0.5079    0.4675       867\n",
            "weighted avg     0.5151    0.5317    0.4818       867\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5313    0.9079    0.6704       467\n",
            "           1     0.3768    0.0650    0.1109       400\n",
            "\n",
            "    accuracy                         0.5190       867\n",
            "   macro avg     0.4541    0.4865    0.3906       867\n",
            "weighted avg     0.4600    0.5190    0.4122       867\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gwVpllNoOiY"
      },
      "source": [
        "## 4.3. Performance Evaluation with Different Input\n",
        "\n",
        "\n",
        "You are required to evaluate with the testing dataset and provide the table with f1 of test set.\n",
        "Note that it will not be marked if you do not display it in the ipynb file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWS3oonaoOiY"
      },
      "source": [
        "(*Please show your empirical evidence and justification*)\n",
        "\n",
        "Empirical evidence:\n",
        "See below code cell's output.\n",
        "\n",
        "Explanation and Justification:\n",
        "1. Trend from tables = The f1 scores were better for continuous bag of words (cbow) (1st table) than for skip-gram (sg) (2nd table). So, cbow is better, as it can better represent more frequent words, and the data's nature might have more frequent words.\n",
        "2. Trend from tables = The macro and weighted avg f1 scores were better for glove-twitter-25 (3rd table) than for glove-wiki-gigaword-50 (4th table). So, glove-twitter-25 is better, as it has higher number of vectors and thus yields better quality.\n",
        "3. Trend from tables = The f1 scores were better for cbow+glove-twitter-25 (5th table) than for sg+glove-wiki-gigaword-50 (6th table). Since glove-twitter-25 was better than glove-wiki-gigaword-50, and cbow was better than sg, this is an obvious result.\n",
        "4. Hence, cbow+glove-twitter-25 have been used in relevant sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTqc1XdioOiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9696809-c70b-4cf7-99a8-630c1a702163"
      },
      "source": [
        "# cbow\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_cbow_model2.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in wv_cbow_model2:\n",
        "        emb_table.append(wv_cbow_model2[word])\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded_1 = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded_1= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_1 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_1)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_1)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_1.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_1(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "model_1.eval()\n",
        "outputs_1 = model_1(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted_1 = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded_1, predicted_1.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "# sg\n",
        "from gensim.models import Word2Vec\n",
        "wv_sg_model1 = Word2Vec(sentences=training_posts1, size=100, window=3, min_count=5, workers=2, sg=1)\n",
        "\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_sg_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in wv_sg_model1:\n",
        "        emb_table.append(wv_sg_model1[word])\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded_2 = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded_2= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_2 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_2.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_2)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_2)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_2.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_2(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "model_2.eval()\n",
        "outputs_2 = model_2(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted_2 = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded_2, predicted_2.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "# glove-twitter-25\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = word_emb_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model1:\n",
        "        emb_table.append(word_emb_model1[word])\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded_3 = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded_3= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_3 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_3.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_3)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_3)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_3.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_3(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "model_3.eval()\n",
        "outputs_3 = model_3(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted_3 = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded_3, predicted_3.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "# glove-wiki-gigaword-50\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "# glove\n",
        "import gensim.downloader as api\n",
        "word_emb_model2 = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = word_emb_model2.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model2:\n",
        "        emb_table.append(word_emb_model2[word])\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded_4 = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded_4= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_4 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_4.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_4)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_4)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_4.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_4(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "model_4.eval()\n",
        "outputs_4 = model_4(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted_4 = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded_4, predicted_4.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "## cbow + glove-twitter-25\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_cbow_model2.vector_size+word_emb_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model1 and word in wv_cbow_model2:\n",
        "        emb_table.append(np.concatenate((wv_cbow_model2[word],word_emb_model1[word]),0))\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded_5 = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded_5= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_5 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_5.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_5)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_5)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_5.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_5(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "model_5.eval()\n",
        "outputs_5 = model_5(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted_5 = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded_5, predicted_5.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "# sg + glove-wiki-gigaword-50\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_sg_model1.vector_size+word_emb_model2.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model2 and word in wv_sg_model1:\n",
        "        emb_table.append(np.concatenate((wv_sg_model1[word],word_emb_model2[word]),0))\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded_6 = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded_6= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_6 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_6.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_6)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_6)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_6.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_6(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "model_6.eval()\n",
        "outputs_6 = model_6(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted_6 = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded_6, predicted_6.cpu().numpy(),digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6621    0.7185    0.6891      4227\n",
            "           1     0.6305    0.5672    0.5972      3581\n",
            "\n",
            "    accuracy                         0.6491      7808\n",
            "   macro avg     0.6463    0.6428    0.6432      7808\n",
            "weighted avg     0.6476    0.6491    0.6470      7808\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:163: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:164: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6271    0.7166    0.6689      4227\n",
            "           1     0.5977    0.4971    0.5428      3581\n",
            "\n",
            "    accuracy                         0.6159      7808\n",
            "   macro avg     0.6124    0.6068    0.6058      7808\n",
            "weighted avg     0.6136    0.6159    0.6110      7808\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5895    0.7223    0.6492      4227\n",
            "           1     0.5534    0.4063    0.4686      3581\n",
            "\n",
            "    accuracy                         0.5774      7808\n",
            "   macro avg     0.5715    0.5643    0.5589      7808\n",
            "weighted avg     0.5730    0.5774    0.5663      7808\n",
            "\n",
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5885    0.7708    0.6674      4227\n",
            "           1     0.5735    0.3639    0.4452      3581\n",
            "\n",
            "    accuracy                         0.5841      7808\n",
            "   macro avg     0.5810    0.5673    0.5563      7808\n",
            "weighted avg     0.5816    0.5841    0.5655      7808\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:557: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:558: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6545    0.7130    0.6825      4227\n",
            "           1     0.6213    0.5557    0.5867      3581\n",
            "\n",
            "    accuracy                         0.6409      7808\n",
            "   macro avg     0.6379    0.6344    0.6346      7808\n",
            "weighted avg     0.6393    0.6409    0.6386      7808\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:687: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:688: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6331    0.7504    0.6868      4227\n",
            "           1     0.6229    0.4867    0.5465      3581\n",
            "\n",
            "    accuracy                         0.6295      7808\n",
            "   macro avg     0.6280    0.6186    0.6166      7808\n",
            "weighted avg     0.6285    0.6295    0.6224      7808\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg08uf3hpyoF"
      },
      "source": [
        "## 4.4. Performance Evaluation with Different Sequence Models\n",
        "\n",
        "\n",
        "You are required to evaluate with the testing dataset and provide the table with f1 of test set.\n",
        "Note that it will not be marked if you do not display it in the ipynb file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e_nVbdrpyoK"
      },
      "source": [
        "(*Please show your empirical evidence and justification*)\n",
        "\n",
        "Empirical evidence: See below code cell's output.\n",
        "\n",
        "Explanation and Justification:\n",
        "1. Trend from tables = The f1 scores for Bi-LSTM (1st table) were better than for Bi-RNN (2nd table). So, Bi-LSTM is better, as it solves the vanishing gradient problem and captures long term dependencies better than Bi-RNN.\n",
        "2. Hence, Bi-LSTM has been used in the relevant sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmbjL4yGpyoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c416c7c8-b2d2-49ba-f77e-013bf4f6f933"
      },
      "source": [
        "# bi-lstm\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_cbow_model2.vector_size+word_emb_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model1 and word in wv_cbow_model2:\n",
        "        emb_table.append(np.concatenate((wv_cbow_model2[word],word_emb_model1[word]),0))\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded_5 = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded_5= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_LSTM = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_LSTM.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_5)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_5)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_LSTM.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_LSTM(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "model_LSTM.eval()\n",
        "outputs_LSTM = model_LSTM(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted_LSTM = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded_5, predicted_LSTM.cpu().numpy(),digits=4))\n",
        "##############################################################################\n",
        "# bi-rnn\n",
        "class Bi_RNN_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_RNN_Model, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "        # set the bidirectional to True\n",
        "        self.rnn = nn.RNN(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(2*n_hidden,n_class)\n",
        "\n",
        "    def forward(self, x):  \n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)       \n",
        "        x, h_n = self.rnn(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        output = self.linear(hidden_out)\n",
        "        return output\n",
        "\n",
        "# Initialize model, set up the loss calculator and optimizer\n",
        "model_RNN = Bi_RNN_Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_RNN.parameters(), lr=learning_rate)\n",
        "\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_5)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_5)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_RNN.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_RNN(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "## Prediction\n",
        "model_RNN.eval()\n",
        "outputs_RNN = model_RNN(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "predicted_RNN = torch.argmax(outputs, 1)\n",
        "\n",
        "# classification_report builds a text report showing the main classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label_encoded_5, predicted_RNN.cpu().numpy(),digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6603    0.7114    0.6849      4227\n",
            "           1     0.6251    0.5680    0.5952      3581\n",
            "\n",
            "    accuracy                         0.6456      7808\n",
            "   macro avg     0.6427    0.6397    0.6400      7808\n",
            "weighted avg     0.6441    0.6456    0.6437      7808\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6480    0.7291    0.6862      4227\n",
            "           1     0.6248    0.5325    0.5750      3581\n",
            "\n",
            "    accuracy                         0.6390      7808\n",
            "   macro avg     0.6364    0.6308    0.6306      7808\n",
            "weighted avg     0.6374    0.6390    0.6352      7808\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P28Z1k36MZuo"
      },
      "source": [
        "## 4.5. HyperParameter Testing\n",
        "*You are required to draw a graph(y-axis: f1, x-axis: epoch) for test set and explain the optimal number of epochs based on the learning rate you have already chosen.* Note that it will not be marked if you do not display it in the ipynb file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYzrA_s2tTaz"
      },
      "source": [
        "(*Please show your empirical evidence and justification*)\n",
        "\n",
        "Empirical evidence: See below code cell's output.\n",
        "\n",
        "Evidence and justification:\n",
        "1. Trend from graphs = Learning rate of 0.001 has the smoothest graph. This shows that it is more precise (scores are closer together) than other rates (0.01 and 0.1). So, 0.001 is a better option, as the other too large learning rates are causing the model to converge too quickly to a suboptimal solution.\n",
        "2. Trend from graphs = The f1 scores gradually become more precise (closer together) and start increasing gradually, as the number of epochs increase. So, 30 is the best option for number of epochs, as there are more updates or corrections made to the model when epoch number is high.\n",
        "3. Hence, the lowest chosen learning rate (0.001) and highest chosen epoch number (30) have been used in the relevant sections. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLyQEeZMZ2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "5a6d5156-c947-4683-e678-b3eb238a03ba"
      },
      "source": [
        "# learning rate = 0.001\n",
        "learning_rate = 0.001\n",
        "# try no. of epochs from 1 to 30\n",
        "total_epoch = 30\n",
        "# for storing f1 scores for different number of epochs\n",
        "f1_1 = []\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_LSTM = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_LSTM.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_5)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_5)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_LSTM.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_LSTM(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "    model_LSTM.eval()\n",
        "    outputs_LSTM = model_LSTM(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "    predicted_LSTM = torch.argmax(outputs, 1)\n",
        "\n",
        "    # classification_report builds a text report showing the main classification metrics\n",
        "    from sklearn.metrics import f1_score\n",
        "    f1_1.append(f1_score(label_encoded_5, predicted_LSTM.cpu().numpy()))\n",
        "\n",
        "# graphing\n",
        "import matplotlib.pyplot as plt\n",
        "ep = list(range(1,total_epoch+1))\n",
        "plt.plot(ep,f1_1,marker='o')\n",
        "plt.title('Peformance trend based on different number of epochs (learning rate = 0.001)')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('f1 score')\n",
        "plt.show()\n",
        "##############################################################################\n",
        "# learning rate = 0.01\n",
        "learning_rate = 0.01\n",
        "# try no. of epochs from 1 to 30\n",
        "total_epoch = 30\n",
        "# for storing f1 scores for different number of epochs\n",
        "f1_2 = []\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_LSTM = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_LSTM.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_5)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_5)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_LSTM.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_LSTM(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "    model_LSTM.eval()\n",
        "    outputs_LSTM = model_LSTM(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "    predicted_LSTM = torch.argmax(outputs, 1)\n",
        "\n",
        "    # classification_report builds a text report showing the main classification metrics\n",
        "    from sklearn.metrics import f1_score\n",
        "    f1_2.append(f1_score(label_encoded_5, predicted_LSTM.cpu().numpy()))\n",
        "\n",
        "# graphing\n",
        "import matplotlib.pyplot as plt\n",
        "ep = list(range(1,total_epoch+1))\n",
        "plt.plot(ep,f1_2,marker='o')\n",
        "plt.title('Peformance trend based on different number of epochs (learning rate = 0.01)')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('f1 score')\n",
        "plt.show()\n",
        "##############################################################################\n",
        "# learning rate = 0.1\n",
        "learning_rate = 0.1\n",
        "# try no. of epochs from 1 to 30\n",
        "total_epoch = 30\n",
        "# for storing f1 scores for different number of epochs\n",
        "f1_3 = []\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model_LSTM = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_LSTM.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded_5)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded_5)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model_LSTM.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_LSTM(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "    model_LSTM.eval()\n",
        "    outputs_LSTM = model_LSTM(torch.from_numpy(np.array(testing_encoded1)).to(device)) \n",
        "    predicted_LSTM = torch.argmax(outputs, 1)\n",
        "\n",
        "    # classification_report builds a text report showing the main classification metrics\n",
        "    from sklearn.metrics import f1_score\n",
        "    f1_3.append(f1_score(label_encoded_5, predicted_LSTM.cpu().numpy()))\n",
        "\n",
        "# graphing\n",
        "import matplotlib.pyplot as plt\n",
        "ep = list(range(1,total_epoch+1))\n",
        "plt.plot(ep,f1_3,marker='o')\n",
        "plt.title('Peformance trend based on different number of epochs (learning rate = 0.1)')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('f1 score')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 - Test your model via Colab Form Fields User Interface"
      ],
      "metadata": {
        "id": "dIfa2nm85H9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are required to design a user interface so that user can input a textual sentence via the colab form fields user interface to get the personality type classification result from your trained model. *You can just modify based on the following Colab Form Fields template*"
      ],
      "metadata": {
        "id": "qrCqpwHD5RG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Personality Type Prediction\n",
        "\n",
        "text = \"I am feeling happy\" #@param {type:\"string\"}\n",
        "##############################################################################\n",
        "# best model\n",
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '16g474hdNsaNx0_SnoKuqj2BuwSEGdnbt'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('training_data.csv')  \n",
        "\n",
        "id = '1-7hj0sF3Rc5G6POKdkpbDXm_Q6BWFDPU'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('testing_data.csv')  \n",
        "\n",
        "import pandas as pd\n",
        "training_data = pd.read_csv(\"/content/training_data.csv\")\n",
        "testing_data = pd.read_csv(\"/content/testing_data.csv\")\n",
        "\n",
        "# Extract the labels and posts and store into List\n",
        "\n",
        "# Get the list of training data (posts)\n",
        "training_posts=training_data['posts'].tolist()\n",
        "# Get the list of corresponding labels for the training data (posts)\n",
        "training_labels=training_data['type'].tolist()\n",
        "\n",
        "# Get the list of testing data (posts)\n",
        "testing_posts=testing_data['posts'].tolist()\n",
        "# Get the list of corresponding labels for the testing data (posts)\n",
        "testing_labels=testing_data['type'].tolist()\n",
        "\n",
        "# need re for matching url\n",
        "import re \n",
        "\n",
        "# method for removing url and doing some basic cleaning/formatting for better experience later\n",
        "def url_remover(tx):\n",
        "    # escape the pipe separators\n",
        "    regex = re.compile('[%s]' % re.escape('|'))\n",
        "    tx = regex.sub(' ',tx)\n",
        "    # deal with words individually and remove those with http (i.e. url)\n",
        "    ws = str(tx).split()\n",
        "    ws = [x for x in ws if not 'http' in x]\n",
        "    # join the words when done, then return them\n",
        "    ws = ' '.join(ws)\n",
        "    return ws\n",
        "\n",
        "# apply the above method\n",
        "training_posts1 = training_data['posts'].apply(url_remover)\n",
        "\n",
        "# need re as earlier\n",
        "import re\n",
        "# remove punctuations and numbers, go lowercase \n",
        "def pln(x):\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    x = re.sub('^\\d+\\s|\\s\\d+\\s|\\s\\d+$','',x)\n",
        "    x = x.lower()\n",
        "    return x\n",
        "training_posts1 = training_posts1.apply(pln)\n",
        "\n",
        "# now, remove stopwords - need nltk for this\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.tokenize import word_tokenize\n",
        "def stopper(x):\n",
        "    tokens = word_tokenize(x)\n",
        "    stop_words = sw.words()\n",
        "    x = [w for w in tokens if not w in stop_words]\n",
        "    return x \n",
        "training_posts1 = training_posts1.apply(stopper)\n",
        "\n",
        "# encoding etc. done later\n",
        "\n",
        "# cbow, more processing done later\n",
        "from gensim.models import Word2Vec\n",
        "wv_cbow_model2 = Word2Vec(sentences=training_posts1, size=100, window=3, min_count=5, workers=2, sg=0)\n",
        "\n",
        "# more data processing\n",
        "word_set_train = set() \n",
        "for sent in training_posts1:\n",
        "    for word in sent:\n",
        "        word_set_train.add(word)\n",
        "\n",
        "# Normally we add the special tokens for representing the padding and unknown words separately\n",
        "# Sometimes we can also use same token to present padding and unknown words if we don't have to differentiate them\n",
        "word_set_train.add('[PAD]')\n",
        "word_set_train.add('[UNKNOWN]')\n",
        "\n",
        "word_list_train = list(word_set_train) \n",
        "\n",
        "# Although in some python versions, converting a set to list will return a ordered result, \n",
        "# It is still highly recommended that you sort this list to ensure the reproducibility of your code\n",
        "word_list_train.sort()\n",
        "\n",
        "word_index_train = {}\n",
        "ind = 0\n",
        "for word in word_list_train:\n",
        "    word_index_train[word] = ind\n",
        "    ind += 1\n",
        "\n",
        "# glove\n",
        "import gensim.downloader as api\n",
        "word_emb_model1 = api.load(\"glove-twitter-25\")\n",
        "\n",
        "import numpy as np\n",
        "emb_dim = wv_cbow_model2.vector_size+word_emb_model1.vector_size\n",
        "\n",
        "# Add the second pre-trained word embedding to the Embedding lookup table via concatenation\n",
        "emb_table = []\n",
        "for i, word in enumerate(word_list_train):\n",
        "    if word in word_emb_model1 and word in wv_cbow_model2:\n",
        "        emb_table.append(np.concatenate((wv_cbow_model2[word],word_emb_model1[word]),0))\n",
        "    else:\n",
        "        emb_table.append([0]*emb_dim)\n",
        "emb_table = np.array(emb_table)\n",
        "\n",
        "seq_length = 16 # otherwise too memory intensive (tried with 128 but got same accuracy anyways)\n",
        "\n",
        "# Padding and encoding\n",
        "def encode_and_add_padding(sentences, seq_length, word_index):\n",
        "    sent_encoded = []\n",
        "    for sent in sentences:\n",
        "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
        "        if len(temp_encoded) < seq_length:\n",
        "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
        "        else:\n",
        "            temp_encoded = temp_encoded[:seq_length]\n",
        "        sent_encoded.append(temp_encoded)\n",
        "    return sent_encoded\n",
        "\n",
        "sent_encoded = encode_and_add_padding(training_posts1, seq_length, word_index_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(training_labels)\n",
        "label_encoded= lEnc.transform(training_labels)\n",
        "\n",
        "vocab_size = len(word_list_train)\n",
        "unique_labels = np.unique(training_labels)\n",
        "n_class = len(unique_labels)\n",
        "n_hidden = 50\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "# Define the model (Bi-LSTM)\n",
        "class Bi_LSTM_Emb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM_Emb, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # [IMPORTANT] Initialize the Embedding layer with the lookup table we created \n",
        "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        # Optional: set requires_grad = False to make this lookup table untrainable\n",
        "        self.emb.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the embeded tensor\n",
        "        x = self.emb(x)        \n",
        "        # we will use the returned h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        # details of the outputs from nn.LSTM can be found from: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        # concat the last hidden state from two direction\n",
        "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        return z\n",
        "\n",
        "# Move the model to GPU\n",
        "model1 = Bi_LSTM_Emb().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "input_torch = torch.from_numpy(np.array(sent_encoded)).to(device)\n",
        "targe_torch = torch.from_numpy(np.array(label_encoded)).view(-1).to(device)\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    model1.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model1(input_torch) \n",
        "    loss = criterion(outputs, targe_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    predicted = torch.argmax(outputs, -1)\n",
        "    acc= accuracy_score(predicted.cpu().numpy(),targe_torch.cpu().numpy())\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# required prediction\n",
        "text_encoded = encode_and_add_padding(text, len(text), word_index_train)\n",
        "model1.eval()\n",
        "outputs_LSTM = model1(torch.from_numpy(np.array(text_encoded)).to(device)) \n",
        "predicted_LSTM = torch.argmax(outputs_LSTM, 1)\n",
        "print('Predicted Personality Type:', end=' ')\n",
        "if (predicted_LSTM.numpy()[0] == 0):\n",
        "    print('T')\n",
        "else:\n",
        "    print('F')"
      ],
      "metadata": {
        "id": "HO_aV5bz5-ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477dfca1-a8f4-49b5-dc26-d3e09e7f150e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:122: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Personality Type: F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfv8rWTKPzeb"
      },
      "source": [
        "# Object Oriented Programming codes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS23AjBRSZaX"
      },
      "source": [
        "*You can use multiple code snippets. Just add more if needed* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hVmx4E52dXS"
      },
      "source": [
        "# If you used OOP style, use this section"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}